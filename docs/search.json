[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Web Mapping and Analysis",
    "section": "",
    "text": "Welcome\nThis is the website for “Web Mapping and Analysis” for the module ENVS456 at the University of Liverpool. This is course designed and delivered by Dr. Elisabetta Pietrostefani and Professor Dani Arribas-Bel from the Geographic Data Science Lab at the University of Liverpool, United Kingdom. The module has two main aims. First, it seeks to to provide hands-on experience and training in the design and generation of web-based mapping and geographical information tools. Second, it seeks to provide hands-on experience and training in the use of software to access, analyse and visualize web-based geographical information.\nThe website is free to use and is licensed under the Attribution-NonCommercial-NoDerivatives 4.0 International. A compilation of this web course is hosted as a GitHub repository that you can access:"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Web Mapping and Analysis",
    "section": "Contact",
    "text": "Contact\n\nDani Arribas-Bel - darribas [at] liverpool.ac.uk Professor in Geographic Data Science Office 6xx, Roxby Building, University of Liverpool - 74 Bedford St S, Liverpool, L69 7ZT, United Kingdom.\n\n\nElisabetta Pietrostefani - e.pietrostefani [at] liverpool.ac.uk Lecturer in Geographic Data Science Office 6xx, Roxby Building, University of Liverpool - 74 Bedford St S, Liverpool, L69 7ZT, United Kingdom."
  },
  {
    "objectID": "structure.html#introduction",
    "href": "structure.html#introduction",
    "title": "Syllabus",
    "section": "Introduction",
    "text": "Introduction\nBlock 1\n\nLecture: Introduction to the module\nLab: Powerful examples"
  },
  {
    "objectID": "structure.html#data-backends",
    "href": "structure.html#data-backends",
    "title": "Syllabus",
    "section": "Data Backends",
    "text": "Data Backends\nBlock 2\n\nLecture: The Web’s architecture and Economy\nLab: What do APIs actually do?\n\nBlock 3\n\nLecture: Data architechtures & formats\nLab: Creating, manipulating, and integrating web geospatial data\n\nBlock 4\n\nLecture: APIs\nLab: Acquiring data from the web"
  },
  {
    "objectID": "structure.html#assignment-i",
    "href": "structure.html#assignment-i",
    "title": "Syllabus",
    "section": "Assignment I",
    "text": "Assignment I\nBlock 5\n\nLecture: Q&A\nLab: Clinic\n\nAssignment I: Combining (geo-)data in an interactive map"
  },
  {
    "objectID": "structure.html#frontend-topics",
    "href": "structure.html#frontend-topics",
    "title": "Syllabus",
    "section": "Frontend Topics",
    "text": "Frontend Topics\nBlock 6\n\nLecture: Map design\nLab: Designing maps with Kepler\n\nBlock 7\n\nLecture: Interactivity\nLab: Designing for interactivity\n\nBlock 8\n\nLecture: Statistical visualisation\nLab: Choropleths in Kepler"
  },
  {
    "objectID": "structure.html#dashboards",
    "href": "structure.html#dashboards",
    "title": "Syllabus",
    "section": "Dashboards",
    "text": "Dashboards\nBlock 9\n\nLecture: Dashboards: bringing analysis to the web\nLab: Building Dashboards (Shiny)\n\nBlock 10\n\nLecture: Technology gallery\nLab: Assignment II clinic\n\nAssignment II: A dashboard of IMD"
  },
  {
    "objectID": "overview.html#aims",
    "href": "overview.html#aims",
    "title": "Overview",
    "section": "Aims",
    "text": "Aims\nThis module aims to:\n\nProvide hands-on experience and training in the design and generation of web-based mapping and geographical information tools.\nProvide hands-on experience and training in the use of software to access, analyse and visualize web-based geographical information."
  },
  {
    "objectID": "overview.html#learning-outcomes",
    "href": "overview.html#learning-outcomes",
    "title": "Overview",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nBy the end of the module, students should be able to:\n\nExperience using tile rendering tools to generate content for map-based web sites.\nKnowledge of web based mapping infrastructure\nWeb-based data collection techniques (accessing Twitter, Facebook, Google and OpenStreetmap information)\nNetwork analysis\nProgramming skills to enable basic online data manipulation and web mapping"
  },
  {
    "objectID": "overview.html#feedback",
    "href": "overview.html#feedback",
    "title": "Overview",
    "section": "Feedback",
    "text": "Feedback\nFormal assessment. Two pieces of coursework (50%/50%). Equivalent to 2,500 words each\nVerbal face-to-face feedback. Immediate face-to-face feedback will be provided during computer, discussion and clinic sessions in interaction with staff. This will take place in all live sessions during the semester.\nTeams Forum. Asynchronous written feedback will be provided via Teams. Students are encouraged to contribute by asking and answering questions relating to the module content. Staff will monitor the forum Monday to Friday 9am-5pm, but it will be open to students to make contributions at all times. Response time will vary depending on the complexity of the question and staff availability."
  },
  {
    "objectID": "overview.html#computational-environment",
    "href": "overview.html#computational-environment",
    "title": "Overview",
    "section": "Computational Environment",
    "text": "Computational Environment\nThis course can be followed by anyone with access to a bit of technical infrastructure. This section details the set of local and online requirements you will need to be able to follow along, as well as instructions or pointers to get set up on your own. This is a centralized section that lists everything you will require, but keep in mind that different blocks do not always require everything all the time.\nTo reproduce the code in the book, you need the most recent version of R and packages. These can be installed following the instructions provided in our R installation guide.\n\nSoftware\nTo run the analysis and reproduce the code, you need the following software:\n\nQGIS- the stable version (3.22 LTR at the time of writing) is OK, any more recent version will also work.\nR-4.2.2\nRStudio 2022.12.0-353\nQuarto 1.2.280\nthe list of libraries in the next section\n\nTo install and update:\n\nQGIS, download the appropriate version from QGIS.org\nR, download the appropriate version from The Comprehensive R Archive Network (CRAN)\nRStudio, download the appropriate version from Posit\nQuarto, download the appropriate version from the Quarto website\n\nTo check your version of:\n\nR and libraries run sessionInfo()\nRStudio click help on the menu bar and then About\nQuarto check the version file in the quarto folder on your computer.\n\n\n\nR List of libraries\nThe list of libraries used in this book is provided below:\n\nsf\ngeojsonsf\nmapview\ntidyverse\ntidycensus\nviridis\nviridisLite\nhttr\njsonlite\nplyr\nwellknown\n\nYou need to ensure you have installed the list of libraries used in this book, running the following code:\n\nlist.of.packages.cran <- c( “sf”, “geojsonsf”, “mapview”, “tidyverse”, “tidycensus”, “viridis”, “viridisLite”, “httr”, “jsonlite”, “plyr”, “wellknown”)\n\n\nnew.packages.cran <- list.of.packages.cran[!(list.of.packages.cran %in% installed.packages()[,“Package”])] if(length(new.packages.cran)) install.packages(new.packages.cran)\n\n\nfor(i in 1:length(list.of.packages.cran)) { library(list.of.packages.cran[i], character.only = T) }\n\n\n\nOnline accounts\n\nCDRC Data: we will use some of the data provided by the CDRC, so a (free) account with them will be necessary.\nMapbox: Mapbox is one of the industry leaders in web mapping. Their free tier is rather generous so will more than suffice for what we will do within the course. You can sign up for a new (free) account here.\nKepler: is a data agnostic, WebGL empowered, high-performance web application for geospatial analytic visualizations."
  },
  {
    "objectID": "assess.html#assignment-i",
    "href": "assess.html#assignment-i",
    "title": "Assessments",
    "section": "Assignment I",
    "text": "Assignment I\n\nTitle: Exploring APIs in R\nType: Coursework\nDue date: Thursday March 2nd, Week 5\n50% of the final mark\nChance to be reassessed\nElectronic submission only\n\nIn this assessment, you will have the opportunity to explore different sources and combine them in a single tileset that can be explored interactively through a web browser. The assignment aims to evaluate your knowledge and aptitude in the following areas:\n\nUnderstanding of core “backend” concepts in web mapping such as tilesets, client-server architecture, or APIs.\nAbility to use the web as a resource for original data.\nDesign skills to present effectively a diverse set of geospatial data in a web map.\n\n\nDesign, data and assemblage.\nThis assignment requires you to source data from the web in different formats, assemble them into a tileset, and document the process. To be successful, you will need to demonstrate your understanding not only of the technical aspects involved in the process, but also of the conceptual notions that underpin them. Below are described the required components for your submission.\nFirst, the design. Start by designing a map for an area you are interested in. There are no clear restrictions but, to ensure you are on the right path, check on your ideas with the module leader, who will be able to assess whether potential problems may arise from your choices. This stage should draw some inspiration from the first weeks of the course, where we looked for examples of web maps and spent time discussing what made them good and why.\nSecond, the data. Draft a list of potential data that would be ideal to use for your map, and try to find out whether they exist and are available. This will be a good guide for which data you will actually end up using. Do not worry about spending a significant amount of time on this aspect; identifying good data takes time and is at the core of this task. Make sure you include both data you can access from direct downloads (e.g. CDRC) and those you download through an API. Once you know which datasets you need, go ahead and do the work required to download them for the map you want to build.\nThird, the assemblage. With all data you have at your disposal from the previous stage, create a tileset that allows to embed the map in an HTML file and explore it through the browser. Pay attention to the design aspects involved in this step too. For example, what is the extent of your map (not necessarily the extent of each of your data)? What are the zoom levels your map will allow? Do you have the same “map” for every zoom level? These are questions you will have to ask (and answer!) yourself to complete this stage successfully.\n\n\nPresentation of your work\nOnce you have created your map, you will need to present it. An important aspect of this stage is that it is not really the map you need to present, but the process of creation you have followed and the design choices you have made that should go into the text. Additionally, you will need to provide evidence that you understand the concepts behind some of the technologies you have used. Write up to 1,000 words and include the following:\n\nMap brief\n\nAbout 250 words introducing the map. This should cover what it tries to represent (what is it about?) and the choices you have made along the way to take that idea into fruition.\nAbout 250 words discussing and motivating the sources of data you have used. Here you should engage not only with what data you are using but why and what they bring to the map. Everything should be in the map for a reason, make sure to spell it out clearly.\n\nConceptual background\n\nAbout 250 words with your description of what an API is, how it works and how it has made your map possible.\nAbout 250 words with your description of how tile-based maps work.\n\n\n\n\nSubmit\nOnce completed, you will need to submit the following:\n\nA static PDF version of an R-markdown. You can either generate this as a pdf directly in Rstudio or generate the html, open it in a browser like Google Chrome and save as a pdf. The pdf should include two parts:\n\nAll your narrative about the map brief and conceptual background.\nAny code you may have used to complete the assignment, documented in detail. NOTE: this section will not contribute towards the word count.\n\nA an .mbtile file containing you tileset.\n\nThe assignment will be evaluated based on four main pillars, on which you will have to be successful to achieve a good mark:\n\nMap design abilities. This includes ideas that were discussed in the course in Blocks 1 and 2.\nTechnical skills. This includes your ability to master technologies that allow you to create a compelling map, but also to access interesting and sophiticated data sources.\nOverall narrative. This assesses your aptitude to introduce, motivate and justify your map, as well as you ability to bring each component of the assignment into a coherent whole that “fits together”.\nConceptual understanding of key technologies presented in the course, in particular of APIs and tile-based mapping.\n\n\n\nHow is this assignment useful?\nThis assessment includes several elements that will help you improve critical aspects of your web mapping skills:\nDesign: this is not about making maps, this is about making good maps. And behind every good map there is a set of conscious choices that you will have to think throug to be successful (what map? what data? how to present the data? etc.). Technology: at the end of the day, building good web maps requires solid understanding of current technology that goes beyond what the average person can be expected to know. In this assignment, you will need to demonstrate you are proficient in a series of tasks manipulating geospatial data in a web environment. Presentation: in many real-world contexts, your work is as good as it can come across to the audience it is intended to. This means that it is vital to be able to communicate not only what you are doing but why and on what building blocks it is based on."
  },
  {
    "objectID": "assess.html#assignment-ii",
    "href": "assess.html#assignment-ii",
    "title": "Assessments",
    "section": "Assignment II",
    "text": "Assignment II\n\nTitle: A dashboard of IMD\nType: Coursework\nDue date: Thursday April 27th, Week 10\n50% of the final mark\nChance to be reassessed\nElectronic submission only\n\nThis assignment requires you to build a dashboard for the Index of Multiple Deprivation. To be successful, you will need to demonstrate your understanding not only of technical elements, but of the design process required to create a product that can communicate complex ideas effectively. There are three core building blocks you will have to assemble to build your dashboard: basemap, main map(s), and widgets. Let us explore each of them more in detail.\nFirst, the basemap. Design your own basemap using Mapbox. Think about the data in the background, which colors, the zoom levels that will be allowed, and how it all comes together to create a backdrop for your main message that is conducent to the experience you want to create. The basemap is like a good side dish: it’s there to make you like the main course even more.\nSecond, the main map(s). One you have your own basemap from Mapbox… move to R. This is where the core of your dashboard should come to shine. What you want to show, how, which interactive elements you will allow the user to access and how they will let them modify the experience of your dashboard. The main course of the meal, make it count!\nThird, additional widgets. One of the advantages of dashboards in comparison to standard web maps is that they allow to bring elements of analysis to a more finished product. Think about what you want your users to be able to analyse, why, and how that will modify the main map. This is the icing on the cake!\n\nSubmit\nOnce completed, you will submit a report through Turnitin that includes the following:\n\nA link to the published dashboard, which needs to be reachable online\nAbout 250 words for the overall idea of the dashboard. What do you want to communicate? What is the story you want to tell?\nAbout 250 words for the data used. Which datasets are you using? Why? What new information do they bring and how they complement each other?\nAbout 250 words to describe your design choices in the basemap and other layers presented (e.g. choropleths).\nAbout 250 words to describe your design choices around interactivity, including both cartographic elements (e.g. zooming, panning) as well as additional interactivity built around components such as widgets.\n\nThe assignment will be evaluated based on:\n\nOverall design of the experience. It is very important you think through every step of preparing this assignment as if it was part of something bigger towards which it contributes. Because that is exactly what it is. Everything should have a reason to be there, and every aspect of the dashboard should be connected to each other following a common thread. And, of course, make this connection and holistic approach come alive in your report.\n(Base)map design. Critically introduce every aspect you have thought about when designing the maps, and explicitly connect it to the overal aim of the dashboard. Be clear in your descriptions and critical in how you engage every design choice.\nInteractivity design. Your dashboard should use interactivity when necessary to deliver a more compelling and fuller experience that better gets your message across. Be sure to clearly lay out in your report which elements are used and why.\nNarrative around the description of the process. Finally, the final mark will also take into account not only how good your dashboard is, but how well you are able to introduce it. Start with the key goals, and then unpack every element in an integrated and compelling way.\n\n\n\nHow is this assignment useful?\nThis assignment combines several elements that will help you improve critical aspects of web mapping:\n\nDesign: this is not about making maps, this is about making good maps. And behind every good map there is a set of conscious choices that you will have to think throug to be successful (what map? what data? how to present the data? etc.).\nTechnology: at the end of the day, building good web maps requires familiarity with the state-of-the-art in terms of web mapping tools. In this assignment, you will need to demonstrate your mastering of some of the key tools that are leading both industry and academia.\nPresentation: in many real-world contexts, your work is as good as it can come across to the audience it is intended to. This means that it is vital to be able to communicate not only what you are doing but why and on what building blocks it is based on."
  },
  {
    "objectID": "assess.html#marking-criteria",
    "href": "assess.html#marking-criteria",
    "title": "Assessments",
    "section": "Marking Criteria",
    "text": "Marking Criteria\nThis course follows the standard marking criteria (the general ones and those relating to GIS assignments in particular) set by the School of Environmental Sciences. Please make sure to check the student handbook and familiarise with them. In addition to these generic criteria, the following specific criteria will be used in cases where computer code is part of the work being assessed:\n\n0-15: the code does not run and there is no documentation to follow it.\n16-39: the code does not run, or runs but it does not produce the expected outcome. There is some documentation explaining its logic.\n40-49: the code runs and produces the expected output. There is some documentation explaining its logic.\n50-59: the code runs and produces the expected output. There is extensive documentation explaining its logic.\n60-69: the code runs and produces the expected output. There is extensive documentation, properly formatted, explaining its logic.\n70-79: all as above, plus the code design includes clear evidence of skills presented in advanced sections of the course (e.g. custom methods, list comprehensions, etc.).\n80-100: all as above, plus the code contains novel contributions that extend/improve the functionality the student was provided with (e.g. algorithm optimizations, novel methods to perform the task, etc.)."
  },
  {
    "objectID": "introduction.html#lecture",
    "href": "introduction.html#lecture",
    "title": "1  Introduction",
    "section": "1.1 Lecture",
    "text": "1.1 Lecture\nSlides can be downloaded “here”"
  },
  {
    "objectID": "introduction.html#lab-powerful-examples",
    "href": "introduction.html#lab-powerful-examples",
    "title": "1  Introduction",
    "section": "1.2 Lab: Powerful examples",
    "text": "1.2 Lab: Powerful examples\nThis lab has two main components:\n\nThe first one will require you to find a partner and work together with her/him\nAnd the second one will involve group discussion.\n\n\n1.2.1 Paired activity\nIn pairs, find three examples where web maps are used to communicate an idea. Complete the following sheet for each example:\n\nSubstantive\n\nTitle: Title of the map/project\nAuthor: Who is behind the project?\nBig idea: a “one-liner” on what the project tries to accomplish –\nMessage: what does the map try to get accross\n\nTechnical\n\nURL:\nInteractivity: does the map let you interact with it in any way? Yes/No\nZoomable: can you explore the map at different scales? Yes/No\nTooltips:\nBasemap: Is there an underlying map providing geographical context? Yes/No. If so, who is it provided by?\nTechnology: can you guess what technology does this map rely on?\n\n\nPost each sheet as a separate item on the Teams channel for Lab No.1\nAs an example, below is the sheet for the project “WHO Coronavirus (COVID-19) Dashboard” \n\nSubstantive\n\nTitle: WHO Coronavirus (COVID-19) Dashboard\nAuthor: World Health Organization\nBig idea: Shows confirmed COVID-19 cases and deaths by country to date\nMessage: The project displays a map of the world where COVID-19 cases are shown by country. This element is used to show which countries have had more cases (large trends). A drop down button allows us to visualise the map by a) Total per 100,000 population b) % change in the last 7 days c) newly reported in the last 7 days d) newly reported in the last 24 hours.\n\nTechnical\n\nURL: https://covid19.who.int/\nInteractivity: Yes\nZoomable: Yes\nTooltips: Yes\nBasemap: No\nTechnology: Unknown\n\n\nHere are a couple of other COVID-19 examples of web-maps that where basemaps and technology is easier to spot.\n\n“London School of Hygiene & Tropical Medicine - COVID-19 tracker”\n“Tracking Coronavirus in the United Kingdom: Latest Map and Case Count”\n\n\n\n1.2.2 Class discussion\nWe will select a few examples posted and collectively discuss (some of) the following questions:\n\nWhat makes them powerful, what “speaks” to us?\nWhat could be improved, what is counter-intuitive?\nWhat design elements do they rely on?\nWhat technology do they use?"
  },
  {
    "objectID": "introduction.html#references",
    "href": "introduction.html#references",
    "title": "1  Introduction",
    "section": "1.3 References",
    "text": "1.3 References\n\nFor an excellent coverage of “visualisation literacy”, Chapter 11 of Andy Kirk’s “Data Visualisation” is a great start. Lab: Getting up to speed for web mapping\nA comprehensive overview of computational notebooks and how they relate to modern scientific work is available on Ch.1 of the GDS book.\nA recent overview of notebooks in Geography is available in Boeing & Arribas-Bel (2021)"
  },
  {
    "objectID": "webarch.html#lecture",
    "href": "webarch.html#lecture",
    "title": "2  Web architecture",
    "section": "2.1 Lecture",
    "text": "2.1 Lecture\nSlides can be downloaded here"
  },
  {
    "objectID": "webarch.html#lab-what-do-apis-actually-do",
    "href": "webarch.html#lab-what-do-apis-actually-do",
    "title": "2  Web architecture",
    "section": "2.2 Lab: What do APIs actually do?",
    "text": "2.2 Lab: What do APIs actually do?\nIn this lab, we will unpack how Application Programming Interfaces (“APIs”) work and we cover the basics of accessing an API using R. Instead of downloading a data set, APIs allow programmers, statisticians (or students) to request data directly from a server to a local machine. When you work with web APIs, two different computers — a client and server — will interact with each other to request and provide data, respectively.\n\n2.2.1 RESTful Web APIs are all around you.\nWeb APIs\n\nAllow you query a remote database over the internet\nTake on a variety of formats\nAdhere to a particular style known as Representation State Transfer or REST (in most cases)\nRESTful APIs are convenient because we use them to query database using URLs\n\nConsider a simple Google search:\n\nEver wonder what all that extra stuff in the address bar was all about? In this case, the full address is Google’s way of sending a query to its databases requesting information related to the search term liverpool top attractions.\n\nIn fact, it looks like Google makes its query by taking the search terms, separating each of them with a +, and appending them to the link https://www.google.com/#q=. Therefore, we should be able to actually change our Google search by adding some terms to the URL:\n\nLearning how to use RESTful APIs is all about learning how to format these URLs so that you can get the response you want.\n\n\n2.2.2 Group activity\nGet into groups of 5 or 6 students. Using your friend the internet, look up answers to the following questions. Each group will be assigned one question and asked to present their findings in 5 min to discuss with the entire class.\n\nWhat is a URL and how can it help us query data? What is a response status and what are the possible categories?\nWhat is a GET request? How does a GET request work?\nWhat are API keys and how do you obtain them? What kinds of restrictions to they impose on users? Find an example of an API key, what does it look like?\n(For 2 groups) More and more APIs pop up every day. Do a bit of quick research and find 2 different examples of APIs that you would be interested in using. 2 groups, 2 or 3 APIs each.\n\n\n\n2.2.3 API R libraries\nThere are two ways to collect data through APIs in R:\nPlug-n-play packages. Many common APIs are available through user-written R Packages. These packages offer functions that conveniently “wrap” API queries and format the response. These packages are usually much more convenient than writing our own query, so it is worth searching for a package that works with the API we need.\nWriting our own API request. If no wrapper function is available, we have to write our own API request and format the response ourselves using R. This is tricky, but definitely doable.\n\n2.2.3.1 tidycensus pair activity\nSome R packages “wrap” API queries and format the response. Lucky us! In pairs, let’s have a look at tidycensus. You can also have a look at the different APIs available from the United States Census Bureau.\ntidycensus is\n- R package first released in mid-2017\n- Allows R users to obtain decennial Census and ACS data pre-formatted for use with with tidyverse tools (dplyr, ggplot2, etc.)\n- Optionally returns geographic data as simple feature geometry for common Census geographies\nCreate a new R-markdown and save it to something you’ll remember, like web_mapping_lab_02.Rmd. To get started working, load the package along with the tidyverse and plyr packages, and set you Census API key. A key can be obtained from http://api.census.gov/data/key_signup.html.\n\nlibrary(plyr)\nlibrary(tidycensus)\nlibrary(tidyverse)\n\n#census_api_key(\"ADD IT HERE\") #replace this with your key\n\n\nVariables in tidycensus are identified by their Census ID, e.g. B19013_001\nEntire tables of variables can be requested with the table argument, e.g. table = “B19001”\nUsers can request multiple variables at a time, and set custom names with a named vector\n\nSearching for variables Getting variables from the US American Community Survey (ACS) 5-Year Data (2016-2020) requires knowing the variable ID - and there are thousands of these IDs across the different files. To rapidly search for variables, use the load_variables() function. The function takes two required arguments: the year of the Census or endyear of the ACS sample, and the dataset name, which varies in availability by year. For the ACS, use either “acs1” or “acs5” for the ACS detailed tables, and append /profile for the Data Profile and /subject for the Subject Tables. To browse these variables, assign the result of this function to a variable and use the View function in RStudio. An optional argument cache = TRUE will cache the dataset on your computer for future use.\n\nview_vars <- load_variables(2020, \"acs5\", cache = TRUE)\n\nview(view_vars)\n\nEXERCISE - In your pairs explore some of the different variables available in the 5-Year ACS (2016-2020). Make a note of 3 variables you would be interested in exploring. The ACS2 variables page might also help.\n\nincome <- get_acs(geography = \"state\", table = \"B19001\") #getting income data by state\nincome\n\n# A tibble: 884 × 5\n   GEOID NAME    variable   estimate   moe\n   <chr> <chr>   <chr>         <dbl> <dbl>\n 1 01    Alabama B19001_001  1888504  5749\n 2 01    Alabama B19001_002   153635  2979\n 3 01    Alabama B19001_003   105415  2397\n 4 01    Alabama B19001_004   106327  2522\n 5 01    Alabama B19001_005   100073  2674\n 6 01    Alabama B19001_006   100569  3023\n 7 01    Alabama B19001_007    96815  2745\n 8 01    Alabama B19001_008    87120  2491\n 9 01    Alabama B19001_009    86181  2124\n10 01    Alabama B19001_010    75721  2512\n# … with 874 more rows\n\n\nEXERCISE - 1) What is a tibble? 2) Discuss the format of the data obtained with your partner and then use the function get_acs to explore the 3 variables you discussed in the previous exercise.\nYou can also get “wide” census data:\n\ninc_wide <- get_acs(geography = \"state\", table = \"B19001\", output = \"wide\")\ninc_wide\n\n# A tibble: 52 × 36\n   GEOID NAME    B1900…¹ B1900…² B1900…³ B1900…⁴ B1900…⁵ B1900…⁶ B1900…⁷ B1900…⁸\n   <chr> <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 42    Pennsy…  5.11e6    8064  296733    3893  206216    3771  223380    3598\n 2 06    Califo…  1.31e7   18542  614887    6699  507398    5286  435382    5251\n 3 54    West V…  7.34e5    2810   62341    2318   43003    1497   45613    1648\n 4 49    Utah     1.00e6    2384   36211    1536   27395    1378   28460    1507\n 5 36    New Yo…  7.42e6   12559  471680    6161  340614    4703  303901    4201\n 6 11    Distri…  2.88e5    1319   24083    1442   11315     809    8300     842\n 7 02    Alaska   2.55e5    1326    9818     613    7476     651    8007     633\n 8 12    Florida  7.93e6   23200  494959    6755  329848    4816  354967    5030\n 9 45    South …  1.96e6    5748  144667    3397   93868    2582   94132    2606\n10 38    North …  3.21e5    1737   18120     846   12664     795   12611     874\n# … with 42 more rows, 26 more variables: B19001_005E <dbl>, B19001_005M <dbl>,\n#   B19001_006E <dbl>, B19001_006M <dbl>, B19001_007E <dbl>, B19001_007M <dbl>,\n#   B19001_008E <dbl>, B19001_008M <dbl>, B19001_009E <dbl>, B19001_009M <dbl>,\n#   B19001_010E <dbl>, B19001_010M <dbl>, B19001_011E <dbl>, B19001_011M <dbl>,\n#   B19001_012E <dbl>, B19001_012M <dbl>, B19001_013E <dbl>, B19001_013M <dbl>,\n#   B19001_014E <dbl>, B19001_014M <dbl>, B19001_015E <dbl>, B19001_015M <dbl>,\n#   B19001_016E <dbl>, B19001_016M <dbl>, B19001_017E <dbl>, …\n\n\nLet’s make our query a bit more precise. We are going to query data on median household income and median age by county in the state of New York from the 2016-2020 ACS.\n\nga_wide <- get_acs(\n  geography = \"county\",\n  state = \"Louisiana\",\n  variables = c(medinc = \"B19013_001\",\n                medage = \"B01002_001\"),\n  output = \"wide\",\n  year = 2020\n)\n\nLet’s plot one of our variables. By default, ggplot organizes the data into 30 bins; this option can be changed with the bins parameter.\n\nggplot(ga_wide, aes(x = medincE)) + \n  geom_histogram(bins = 15) #argument bins = 15 in our call to geom_histogram()\n\n\n\n\nWe can also easily explort correlations between variables. The geom_point() function, which plots points on a chart relative to X and Y values for observations in a dataset. This requires specification of two columns in the call to aes().\n\nggplot(ga_wide, aes(x = medageE, y = medincE)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\nEXERCISE - In your pairs, modify the state, vairables and year parametres in your get_acs function and produce some other simple scatter plots (cloud of points) that suggest correlations between your variables of interest.\nYou can also directly map data you have queried in tidycensus. We will look at this in future sessions. For a complete overview of tidycensus please see Analyzing US Census Data: Methods, Maps, and Models in R.\n\n\n2.2.3.2 Your own API request demo\nThe R libraries that are often used for APIs are httr and jsonlite. They serve different roles in our introduction of APIs, but both are essential.\nJSON stands for JavaScript Object Notation. While JavaScript is another programming language. JSON is useful because it is easily readable by a computer, and for this reason, it has become the primary way that data is transported through APIs. Most APIs will send their responses in JSON format. Using the jsonlite package, you can extract and format data into an R dataframe. JSON is a structure formatted with a key (for example, a variable name id) and a value (BikePoints_308). We used the function fromJSON to transform the API request content into a useable dataframe.\nWe will request the locations of all the hire bike stations in London from the Transport for London API. We use the GET function from httr package.The GET() function requires a URL, which specifies the server’s address to which the request needs to be sent.\n\nlibrary(httr)\nlibrary(jsonlite)\n\n#key <- \"YOURKEY HERE\"\nrequest <- GET(\"https://api.tfl.gov.uk/BikePoint/\") # Here we request all the bike docking stations from the Transport for London API\n\n\nrequest # Examine output\n\nResponse [https://api.tfl.gov.uk/BikePoint/]\n  Date: 2023-02-06 19:09\n  Status: 200\n  Content-Type: application/json; charset=utf-8\n  Size: 2.17 MB\n\n\n\nrequest$status_code # The response status is 200 for a successful request\n\n[1] 200\n\n\nMost GET request URLs for API querying have three or four components:\n\nAuthentication Key/Token: A user-specific character string appended to a base URL telling the server who is making the query; allows servers to efficiently manage database access.\nBase URL: A link stub that will be at the beginning of all calls to a given API; points the server to the location of an entire database.\nSearch Parameters: A character string appended to a base URL that tells the server what to extract from the database; basically a series of filters used to point to specific parts of a database.\nResponse Format: A character string indicating how the response should be formatted; usually one of .csv, .json, or .xml.\n\n\nbikepoints <- jsonlite::fromJSON(content(request, \"text\")) # extract the dataframe\nnames(bikepoints) # Print the column names\n\n [1] \"$type\"                \"id\"                   \"url\"                 \n [4] \"commonName\"           \"placeType\"            \"additionalProperties\"\n [7] \"children\"             \"childrenUrls\"         \"lat\"                 \n[10] \"lon\"                 \n\nbikepoints$`Station ID` = as.numeric(substr(bikepoints$id, nchar(\"BikePoints_\")+1, nchar(bikepoints$id))) # create new ID\n\nAfter Block 3 Data architectures we will have revised spatial data forms and you will easily be able to map data that you have obtained through this API.\n\n## Create an sf object from longitude latitude\nlibrary(dplyr)\nlibrary(sf)\nlibrary(tmap)\n# create a sf object\nstations_df <- bikepoints %>% \n  sf::st_as_sf(coords = c(10,9))  %>%  # create pts from coordinates\n  st_set_crs(4326) %>%  # set the original CRS\n  relocate(`Station ID`) # set ID as the first column of the dataframe\n\n# plot bikepoints on a background map for more context\ntmap_mode(\"view\")\ntm_basemap() +\n  tm_shape(stations_df) +\n  tm_symbols(id = \"commonName\", col = \"red\", scale = .5)"
  },
  {
    "objectID": "webarch.html#group-activity-answers",
    "href": "webarch.html#group-activity-answers",
    "title": "2  Web architecture",
    "section": "2.3 Group activity answers",
    "text": "2.3 Group activity answers\n\nUniform Resource Location (URL) is a string of characters that, when interpreted via the Hypertext Transfer Protocol (HTTP). URLs point to a data resource, notably files written in Hypertext Markup Language (HTML) or a subset of a database\n\n1xx informational response - the request was received, continuing process\n2xx successful - the request was successfully received, understood, and accepted\n3xx redirection - further action needs to be taken in order to complete the request\n4xx client error - the request contains bad syntax or cannot be fulfilled\n5xx server error - the server failed to fulfil an apparently valid request\n\nGET requests a representation of a data resource corresponding to a particular URL. The process of executing the GET method is often referred to as a GET request and is the main method used for querying RESTful databases. HEAD, POST, PUT, DELETE: other common methods, though mostly never used for database querying.\nSurfing the web is basically equivalent to sending a bunch of GET requests to different servers and asking for different files written in HTML. Suppose, for instance, I wanted to look something up on Wikipedia. Your first step would be to open your web browser and type in http://www.wikipedia.org. Once you hit return, you would see the page below. Several different processes occured, however, between you hitting “return” and the page finally being rendered:\n\nThe web browser took the entered character string, used the command-line tool “Curl” to write a properly formatted HTTP GET request, and submitted it to the server that hosts the Wikipedia homepage.\nAfter receiving this request, the server sent an HTTP response, from which Curl extracted the HTML code for the page (partially shown below).\nThe raw HTML code was parsed and then executed by the web browser, rendering the page as seen in the window.\nMost APIs requires a key or other user credentials before you can query their database. Getting credentialised with a API requires that you register with the organization. Once you have successfully registered, you will be assigned one or more keys, tokens, or other credentials that must be supplied to the server as part of any API call you make. To make sure users are not abusing their data access privileges (e.g., by making many rapid queries), each set of keys will be given rate limits governing the total number of calls that can be made over certain intervals of time.\n\nMost APIs requires a key before you can query their database. This usually requires you to register with the organization. Most APIs are set up for developers, so you will likely be asked to register an “application.” All this really entails is coming up with a name for your app/bot/project and providing your real name, organization, and email. Note that some more popular APIs (e.g., Twitter, Facebook) will require additional information, such as a web address or mobile number. Once you have registered, you will be assigned one or more keys, tokens, or other credentials that must be supplied to the server as part of any API call you make. Most API keys limits he total number of calls that can be made over certain intervals of time. This is so users do not busing their data access privileges."
  },
  {
    "objectID": "webarch.html#references",
    "href": "webarch.html#references",
    "title": "2  Web architecture",
    "section": "2.4 References",
    "text": "2.4 References\n\nBrief History of the Internet, by the Internet Society, is a handy (and free!) introduction to how it all came to be.\nHaklay, M., Singleton, A., Parker, C. 2008. “Web Mapping 2.0: The Neogeography of the GeoWeb”. Geography Compass, 2(6):2011–2039\nA blog post from Joe Morrison commenting on the recent change of licensing for some of the core software from Mapbox\nTerman, R., 2020. Computational Tools for Social Science\nWalker, K. Analyzing US Census Data: Methods, Maps, and Models in R."
  },
  {
    "objectID": "dataarch.html#lecture",
    "href": "dataarch.html#lecture",
    "title": "3  Data architectures",
    "section": "3.1 Lecture",
    "text": "3.1 Lecture\nSlides can be downloaded here"
  },
  {
    "objectID": "dataarch.html#lab-creating-manipulating-and-integrating-web-geo-spatial-data",
    "href": "dataarch.html#lab-creating-manipulating-and-integrating-web-geo-spatial-data",
    "title": "3  Data architectures",
    "section": "3.2 Lab: Creating, manipulating, and integrating web geo-spatial data",
    "text": "3.2 Lab: Creating, manipulating, and integrating web geo-spatial data\nIn this lab, we will explore and familiarise with some of the most common data formats for web mapping: GeoJSON and Mbtiles. To follow this session, you will need to be able to access the following:\n\nThe internet\nQGIS. Any version should work in this context, but if you are installing it on your computer, QGIS 3.22 is recommended\nThe R libraries listed in the computational environment setup of the course.\n\n\n3.2.1 GeoJSON\nTo get familiar with the format, we will start by creating a GeoJSON file from scratch. Head over to the following website:\nhttps://geojson.io/\nIn there, we will create together a small example to better understand the building blocks of this file format.\n\n\n\ngeojson.io\n\n\nWe will pay special attention to the following aspects:\n\nReadability\nCoordinate system\nAbility to add non-spatial information attached to each record\nHow to save it as a file\n\nEXERCISE\nCreate a GeoJSON file for the following data and save them to separate files:\n\nYour five favourite spots in Liverpool\nA polygon of what you consider to be the boundary of the neighbourhood where you live and the city centre of Liverpool. Name each.\nA route that captures one of your favorite walks around the Liverpool region\n\nIf you are comfortable, upload the files to Microsoft Teams to share them with peers.\n\n\n3.2.2 GeoJSON in R\nWith the files from the exercise at hand, we will then learn how to open them in R-markdown. Create a new R-markdown and save it to something you’ll remember, like web_mapping_lab_03.Rmd.\nThen let’s start by calling the libraries sf and geojsonsf :\n\n# Simple features, a standardized way to encode spatial vector data\nlibrary(sf) \n# Converts Between GeoJSON and simple feature objects\nlibrary(geojsonsf) \n\nNow, place the .geojson files you have created in the same folder where you are storing the R-markdown, or somewhere reachable. For this example, we will assume that the file is called map.geojson and it is stored in the data folder, accessible from the same location where the notebook is. We can read the file as:\n\nliverpool <- geojson_sf(\"data/map.geojson\")\n\nWe can inspect the file to see what it contains:\n\nhead(liverpool)\n\nSimple feature collection with 4 features and 0 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -2.977367 ymin: 53.39987 xmax: -2.954183 ymax: 53.40753\nGeodetic CRS:  WGS 84\n                        geometry\n1 POLYGON ((-2.965248 53.4016...\n2 LINESTRING (-2.975764 53.40...\n3     POINT (-2.977367 53.40753)\n4 POLYGON ((-2.958036 53.4009...\n\n\nIf you are familiar with sf objects, this is exactly it, read straight from a GeoJSON file (if you need a refresher, you can check out introduction to sf) in the Spatial Data Science book.\n A point is single point geometry: POINT (5 2)\n A line string is a sequence of points with a straight line connecting the points: LINESTRING (1 5, 4 4, 4 1, 2 2, 3 2)\n A polygon is a sequence of points that form a closed ring without intersection. Closed means that the first and the last point of a polygon have the same coordinates: POLYGON ((1 5, 2 2, 4 1, 4 4, 1 5))\nLet’s quickly plot the sf object to visualise it in R.\n\n# Provides functions to very quickly and conveniently create interactive visualisations of spatial data.\nlibrary(mapview) \nmapview(liverpool)\n\n\n\n\n\n\nOnce read, the geojson behaves exactly like any sf objects, we can therefore operate on it and tap into the functionality from sf. For example, we can inspect the Coordinate Reference System (CRS) in which it is expressed:\n\nst_crs(liverpool)\n\nCoordinate Reference System:\n  User input: 4326 \n  wkt:\nGEOGCS[\"WGS 84\",\n      DATUM[\"WGS_1984\",\n        SPHEROID[\"WGS 84\",6378137,298.257223563,\n          AUTHORITY[\"EPSG\",\"7030\"]],\n        AUTHORITY[\"EPSG\",\"6326\"]],\n      PRIMEM[\"Greenwich\",0,\n        AUTHORITY[\"EPSG\",\"8901\"]],\n      UNIT[\"degree\",0.0174532925199433,\n        AUTHORITY[\"EPSG\",\"9122\"]],\n      AXIS[\"Latitude\",NORTH],\n      AXIS[\"Longitude\",EAST],\n    AUTHORITY[\"EPSG\",\"4326\"]]\n\n\nUsing some of sf’s functionality. We can reproject it to express it in metres:\n\n# Transform to British National Grid\nliverpool_bng <- st_transform(liverpool, st_crs(27700)) \n# To check the new projection\nst_crs(liverpool_bng)\n\nCoordinate Reference System:\n  User input: EPSG:27700 \n  wkt:\nPROJCRS[\"OSGB36 / British National Grid\",\n    BASEGEOGCRS[\"OSGB36\",\n        DATUM[\"Ordnance Survey of Great Britain 1936\",\n            ELLIPSOID[\"Airy 1830\",6377563.396,299.3249646,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4277]],\n    CONVERSION[\"British National Grid\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",49,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",-2,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996012717,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",400000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",-100000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"United Kingdom (UK) - offshore to boundary of UKCS within 49°45'N to 61°N and 9°W to 2°E; onshore Great Britain (England, Wales and Scotland). Isle of Man onshore.\"],\n        BBOX[49.75,-9,61.01,2.01]],\n    ID[\"EPSG\",27700]]\n\n\nWhen we inspected our geojson with head(liverpool) we noted that the spatial data is stored in the following format: POINT (-2.977367 53.40753). This is called “well known text” (wkt) and is a representation that spatial databases like PostGIS use as well. Another way to store spatial data as text for storage or transfer, less (human) readable but more efficient is the “well known blurb” (wkb). In R, you can transform wkt data into wkb data using the library wellknownand the function wkt_wkb.\n\nlibrary(wellknown) # Convert Between 'WKT' and 'GeoJSON'\n\n# Load the WKT representation of the point and convert the WKT representation into WKB format\nwkt <- wkt_wkb(\"POINT (-2.977367 53.40753)\")\n\n# Print the WKB data\nwkt\n\n [1] 01 01 00 00 00 5e 84 29 ca a5 d1 07 c0 c7 11 6b f1 29 b4 4a 40\n\n\nAnother benefit of reading data in R is we can use its analytical capabilities. For example, we can calculate the length of a line our data frame:\n\n# Extract the second row, which is a line, and reconvert to sf object\nliverpool_walk <- st_sf(liverpool_bng[2,])\n\n# Calculate the length of the linestring\nst_length(liverpool_walk)\n\n800.678 [m]\n\n\nGiven the the line is expressed in metres (check out EPSG:27700), we can conclude the line spans about 800.678 metres,\nEXERCISE\n\nRead the GeoJSON created for your favorite walks in Liverpool and calculate their length\nPro: explore the R documentation and try to extract the area for the polygon covering your neighbourhood\n\nOnce you are happy with the data as we will hypothetically need it, you can write it out to any other file format supported in sf. For example, we can create a Geopackge file with the same information. For this, we can use the function st_write. The file name is taken as the data source name. The default for the layer name is the basename (filename without path) of the the data source name. See an example below:\n\n## Writing layer `liverpool_bng' to data source `liverpool_bng.gpkg' using driver `Geopackge'\nst_write(liverpool_bng, dsn = \"data/liverpool_bng.gpkg\", layer = \"data/liverpool_bng.gpkg\", driver = \"GPKG\", delete_dsn = TRUE)\n\nDeleting source `data/liverpool_bng.gpkg' using driver `GPKG'\nWriting layer `data/liverpool_bng.gpkg' to data source \n  `data/liverpool_bng.gpkg' using driver `GPKG'\nWriting 4 features with 0 fields and geometry type Unknown (any).\n\n\nR’s sf cheatsheet is a good reference for manipulation operations/spatial predicates with simple features.\n\n\n3.2.3 Tilesets and Mbtiles\nIn this section we will dive into the concept of tiles to understand why they have been so transformative in the world of web mapping. We have already seen several tilesets. If you scroll back up where we used the function mapview, you will see that is it plotting out points, polygons and linestrings on different tileset options integrated in the library.\n\nWe will learn how to prepare a map that is styled in QGIS and then saved as either an .mbtiles file of a structured folder with tiles that allows to serve it over the web in efficient ways. Finally we will explore the tileset built using the JavaScript library Leaflet.js.\nBefore we get started, let’s get all the required pieces together:\n\nFire up QGIS 3\nDownload the data here\n\nBuild your basemap\nBasemaps are maps that provide context to more specific spatial data you might want to present. For example, if you have a set of points that represent events in space, it might be hard to understand their distribution unless you put them in the context of a more complete geography. A basemap is a quick solution in this case.\nExplore the layers provided in the GeoData Pack and select those you want to use for your basemap. Once ready, go ahead and add them as layers in QGIS. Tweak colors, transparencies, linewidths, etc. until you get a map you are happy with.\n\nCreate a tileset for your map\nOnce ready to build the basemap from your created map, head over to Processing Toolbox and select the Raster tools --> Generate XYZ Tiles (Directory). You can start with the Directory option. Pick parameters and, when everything is ready, hit Run. Depending on your settings, this will take some time, be patient.\n\nWhen finished, QGIS will have created a folder with a particular structure, that contains all the tiles required to serve your basemap. You can peak into them to find they are really just images of different parts of your map at different zoom levels.\nExplore your basemap with Leaflet.js\nIf you store your basemap in a folder, QGIS will also generate for you a HTML file with a bit of JavaScript code that will allow you to explore the tileset in a browser. Play with it a little bit and familiarise with the look and feel of it.\n\nIf you feel adventurous, you can also peak into the code that makes the web map possible. To do that, you will need to either open the HTML file on a text editor, or inspect the source code from the browser (in Chrome, for example, this can be accessed through Right Click --> Inspect.\nCreate a .mbtiles file for easy transport\nFinally, you can recreate the process above but in this case choosing the MBTiles instead of the Directory option. This will make QGIS generate the same tileset but, instead of storing it directly on a folder, it will save it as a SQLite database in with the .mbtiles format. This is easier to move from one environment to another and is also supported by most web mapping platforms, such as Mapbox.\n.mbtiles in R\nFor this next section, you will need to register for a MapBox account. here.\nFollowing from the previous exercise, save a file of Liverpool buildings as a geojson and call it buildings_liverpool.geojson.\n\n# R Interface to 'Mapbox' Web Services\nlibrary(mapboxapi)\n\nUsage of the Mapbox APIs is governed by the Mapbox Terms of Service.\nPlease visit https://www.mapbox.com/legal/tos/ for more information.\n\n# Mapdeck is a combination of Mapbox and Deck.gl. Deck.gl is one of the most user-friendly WebGL javascript libraries and can produce some beautiful maps. And it integrates nicely with Mapbox.\nlibrary(mapdeck)\n#Tools for Working with URLs and HTTP\nlibrary(httr)\n\nYou can use tippecanoe to make a dynamic .mbtiles files in R, just like the XYZ function in QGIS. This is useful to visualize large data appropriately at any zoom level. sf objects can also be used as input! This requires you to install tippecanoe on your machine separately first. See instructions here.\n\n# Using tippecanoe to create .mbtiles of building footprint liverpool\ntippecanoe(input = \"data/buildings_liverpool.geojson\",\n           output = \"data/buildings_liverpool.mbtiles\",\n           layer_name = \"buildings_liverpool\")\n\nYou can then upload the generated tilesetwith the upload_tiles() function to your Mapbox account (requires a Mapbox secret access token to be set as an environment variable). Or you can upload this manually.\n\nHead over to Mapbox Studio\nStart a New Style and chose a template (Monochrome, blank etc.) \nUpload the data and style it\n\n\nIt should look like a nicer version of this:\n\nWhen you’ve styled it, bring it back into your R project\n\n\n\n\n# Define your mapbox token\n#my_token <- \"PLACE YOUR MAPBOX TOKEN HERE and UNCOMMENT\"\n\n# Into R with mapdeck by referencing the style ID.\nmapdeck(token = my_token, \n        # Replace the style with the one you've created\n        style = \"mapbox://styles/pietrostefanie/cle4dgs2o002d01tft37b5ndg\",\n        zoom = 10,\n        location = c(-2.973286, 53.406872))"
  },
  {
    "objectID": "dataarch.html#references",
    "href": "dataarch.html#references",
    "title": "3  Data architectures",
    "section": "3.3 References",
    "text": "3.3 References\n\nPebesma, E. & Bivand, R. (2022) Spatial Data Science with applications in R\nChapter 3 of the GDS book (in progress) covers traditional and more modern approaches to represent Geography as data.\nKitchin, R. (2014). The data revolution: Big data, open data, data infrastructures and their consequences. Sage.\nMaptiler.com documents on map tiles and map vector tiles."
  },
  {
    "objectID": "apis.html#lecture",
    "href": "apis.html#lecture",
    "title": "4  APIs",
    "section": "4.1 Lecture",
    "text": "4.1 Lecture\nSlides can be downloaded here"
  },
  {
    "objectID": "apis.html#lab-acquiring-data-from-the-web.",
    "href": "apis.html#lab-acquiring-data-from-the-web.",
    "title": "4  APIs",
    "section": "4.2 Lab: Acquiring data from the web.",
    "text": "4.2 Lab: Acquiring data from the web.\nIn this lab, we will interact with a few APIs to get a feel for how they work and how you can make the most of them when trying to access data on the web. To follow this session, you will need to be able to access the following:\n\nThe internet\nA Mapbox API token, which you can access through your Mapbox account. If you haven’t signed up, do this before class here.\nThe R libraries listed in the computational environment setup of the course.\n\n\n4.2.1 Basemap API\nThis section will cover the access of basemaps served as tilesets through the standard XYZ protocol. For this, we will use the library leaflet. It is an open-source Javascript library and a popular option for creating interactive mobile-friendly maps. We will use it first as end-users, and then we will peak a bit into its guts to get a better understanding of its inner workings.\nLeaflet provider list - The leaflet packages comes with 100+ provider tiles - The names of these tiles are stores in a list named providers\nAs a convenience, leaflet also provides a named list of all the third-party tile providers that are supported by the plugin. This enables you to use auto-completion feature of your favorite R IDE (like RStudio) and not have to remember or look up supported tile providers; just type providers$ and choose from one of the options. You can also use names(providers) to view all of the options. Notice how the names of the tiles appear.\nThe XYZ protocol exposes maps as images for portions of the Earth we will call tiles. The XYZ name stands from the “coordinates” used to locate a given tile. This of the entire planet split up into squares, each of them available with a unique combination of X and Y numbers. Now add a third one (Z) for the zoom level: lower values use less tiles to cover the world, while higher resolution levels (higher Z) will cover progressively smaller areas, but with more detail. Most XYZ APIs expose tiles directly over HTTP, which means we can access them from the browser.\n\nlibrary(leaflet)\n# To see the first 5 provider tiles\nnames(providers[1:5])\n\n[1] \"OpenStreetMap\"        \"OpenStreetMap.Mapnik\" \"OpenStreetMap.DE\"    \n[4] \"OpenStreetMap.CH\"     \"OpenStreetMap.France\"\n\n\nIf you want to see the tiles of only one provide you can use the str_detect function.\n\nlibrary(tidyverse)\n# To see all the Open Street Map tiles\nnames(providers)[str_detect(names(providers), \"OpenStreetMap\")]\n\n[1] \"OpenStreetMap\"        \"OpenStreetMap.Mapnik\" \"OpenStreetMap.DE\"    \n[4] \"OpenStreetMap.CH\"     \"OpenStreetMap.France\" \"OpenStreetMap.HOT\"   \n[7] \"OpenStreetMap.BZH\"   \n\n\nTo add a basemap, we just define the tile with addProviderTiles()\n\nleaflet() %>%  \n  # addTiles()  \n  addProviderTiles(\"Stamen.TonerLite\") \n\n\n\n\n\nZooming to a default map view\n\nleaflet() %>%  \n  # addTiles()  \n  addProviderTiles(\"Stamen.TonerLite\") %>% \n  # define set view with coordinates\n  setView(lng = -2.967212, lat = 53.406045, zoom = 13)\n\n\n\n\n\nAdding markers and popups (tooltips) and changing\n\npopup = c(\"Tom\", \"Kendall\", \"Sean\", \"Zachary\", \"Karla\")\nleaflet() %>%\n  addProviderTiles(\"NASAGIBS.ViirsEarthAtNight2012\") %>%\n  addMarkers(lng = c(-3.2031323, -0.2416811, -3.4924087, -4.3725404, -2.6607571),\n             lat = c(53.4118332, 51.5285582, 55.940874, 55.8553807, 51.4684681), \n             popup = popup)\n\n\n\n\n\nPlotting multiple points and storing the map as an R object\n\n# Built a dataframe with tibble\nhometown <- tibble(\nstudent = c(\"Tom\", \"Kendall\", \"Sean\", \"Zachary\", \"Karla\", \"Lois\"),\nlon = c(-3.2031323, -0.2416811, -3.4924087, -4.3725404, -2.6607571, -1.6395383),\nlat = c(53.4118332, 51.5285582, 55.940874, 55.8553807, 51.4684681, 53.3956347))\nleaflet() %>%\naddProviderTiles(\"Stamen.TonerLite\") %>%\n  # Add markers according to dataframe\naddMarkers(lng = hometown$lon, lat = hometown$lat)\n\n\n\n\n\nFor some extra help with leaflet in R have a look here.\n\n\n4.2.2 Mapbox Static Tiles API\nThe Mapbox Static Tiles API serves raster tiles generated from Mapbox Studio styles. Raster tiles can be used in traditional web mapping libraries like Mapbox.js, Leaflet, OpenLayers, and others to create interactive slippy maps. The Static Tiles API is well-suited for maps with limited interactivity or use on devices that do not support WebGL.\n\n# R Interface to 'Mapbox' Web Services\nlibrary(mapboxapi)\n\nUsage of the Mapbox APIs is governed by the Mapbox Terms of Service.\nPlease visit https://www.mapbox.com/legal/tos/ for more information.\n\n\n\n# my_token <- \"PLACE YOUR MAPBOX TOKEN HERE and UNCOMMENT\"\n# mb_access_token(my_token, overwrite = TRUE, install = TRUE)\n# readRenviron(\"~/.Renviron\")\n\nleaflet() %>% \n  addMapboxTiles(style_id = \"light-v9\", username = \"mapbox\" ) %>% \n  setView( lng =-2.973286, lat = 53.406872, zoom = 13 )\n\n\n\n\n\nYou could also call on a basemap you made yourself as shown in the Data Architecture of the course.\nEXERCISE\n\nExplore different basemaps with addProviderTiles() in the leaflet library or with mapboxapi\nSet a fixed boundary with the function fitBounds() and setMaxBounds(). You can explore bounding boxes (coordinates) here - Think about data you would could plot on it and why.\nWhen selecting a Basemap ask yourself some questions\n\nWhy are you making this map?\nIs it just for your use or within a bigger project?\nWhat type of data will you be plotting?\n\nIn pairs , present your choice of basemap and webmap idea to your partner.\n\nSome Extras - Leaflet.extras2 has some nice additions to the leaflet library. For example, you can integrate easy slide views between two maps. - Mapview is a great library that generates interactive maps with very little code. You can find tutorials here and here\n\n\n4.2.3 Directions API\nWe will explore an API that allows us to tap into the output of computations that take place in the cloud, rather than a direct database. In particular, we will play with the Mapbox Directions API. You will need your mapbox token again\nMapboxapi supports the use of Mapbox’s Directions, Isochrone, Matrix, and more, and are designed to be incorporated into R analysis workflows using sf, Shiny, and other packages.\nThe mb_directions() function computes a route between an origin and destination, or along multiple points in an sf object. Output options include the route or the route split by route legs as an sf linestring, or the full routing output as an R list for additional applications.\nThe general structure of the call is as follows:\n\nmy_route <- mb_directions( origin = \"140 Chatham St, Liverpool L7 7BA\", destination = \"4 Stanley St, Liverpool L1 6AA\", profile = \"cycling\", steps = TRUE) \n\nleaflet(my_route) %>% \n  addMapboxTiles( style_id = \"light-v9\", username = \"mapbox\" ) %>%\n  addPolylines()\n\n\n\n\n\nIt can even give us directions - in multiple languages\n\nmy_route$instruction\n\n [1] \"Head north on Chatham Street\"               \n [2] \"Turn right onto Myrtle Street\"              \n [3] \"Continue straight to stay on Myrtle Street\" \n [4] \"Turn left onto Melville Place\"              \n [5] \"Turn right onto Oxford Street\"              \n [6] \"Continue onto Grinfield Street\"             \n [7] \"Continue onto Chatham Place\"                \n [8] \"Continue onto Harbord Street\"               \n [9] \"Turn left onto Chatsworth Drive\"            \n[10] \"Turn left onto Wavertree Road (B5178)\"      \n[11] \"Turn right onto Dorothy Drive\"              \n[12] \"Turn right onto Royston Street\"             \n[13] \"Turn left onto Durning Road (B5173)\"        \n[14] \"Turn right onto Edge Lane (A5047)\"          \n[15] \"Turn left onto Gresham Street\"              \n[16] \"Continue straight to stay on Gresham Street\"\n[17] \"Continue straight onto Gresham Street\"      \n[18] \"Turn right onto Edge Grove\"                 \n[19] \"Turn left onto Stanley Street\"              \n[20] \"You have arrived at your destination\"       \n\n\nExercise\n\nExplore the documentation and play around with some of the mb_directions(). Which other profiles can you pick? try out some languages for example by adding language = \"fr\"\nExplore the documentation for the isochrone on mapboxapi and try to obtain results - mb_isochrone(). For example, retrieve the area that can be reached within 15 minutes of the Roxby Building. Isochrones are areas reachable within a given travel time, around a given location.\nPlay around with travel-time matrices with the mb_matrix() function\n\nNote that there are other routing APIs available such as library(osrm).\n\n\n4.2.4 Geographic Data through APIs and the web\nWe’ve share spatial data through APIs. Let’s now have a look at how APIs can help us generate and create spatial data.\nIn the Web Architecture section of the module, you already had a look at API requests. We used both:\n\nWriting our own API request. The GET function from httr package.\nPlug-n-play packages. get functions available through user-written R Packages\n\nThere are many APIs where we can GET data these days. A few examples are:\n\nUS CENSUS API\nOverpass API - Open Street Map\nTransport for London API\nThe London DataStore API\nThames Water API\nLondon Air API\nCrime data\n\nAnother good source of data is the CDRC\nLet’s go back to the Bike Points example we starting looking at in the Web’s architecture session.\n\nlibrary(httr)\nlibrary(jsonlite)\n\n#key <- \"YOURKEY HERE\"\n\nrequest <- GET(\"https://api.tfl.gov.uk/BikePoint/\") # Here we request all the bike docking stations from the Transport for London API\n\nChecking the Status Code\n\n# The response status is 200 for a successful request\nrequest$status_code \n\n[1] 200\n\n\nExtracting the data frame\n\nbikepoints <- jsonlite::fromJSON(content(request, \"text\")) # extract the dataframe\nnames(bikepoints) # Print the column names\n\n [1] \"$type\"                \"id\"                   \"url\"                 \n [4] \"commonName\"           \"placeType\"            \"additionalProperties\"\n [7] \"children\"             \"childrenUrls\"         \"lat\"                 \n[10] \"lon\"                 \n\nbikepoints$`Station ID` = as.numeric(substr(bikepoints$id, nchar(\"BikePoints_\")+1, nchar(bikepoints$id))) # create new ID\n\nCreating an sf object from longitude latitude in the bike dataframe.\n\nlibrary(dplyr)\nlibrary(sf)\n\n# create a sf object and set the CRS\nstations_df <- bikepoints %>% \n  sf::st_as_sf(coords = c(10,9))  %>%  # create pts from coordinates\n  st_set_crs(4326) %>%  # set the original CRS\n  relocate(`Station ID`) # set ID as the first column of the dataframe\n\nNow let’s add some data about trips made by hire bikes. We need to use the station IDs for the beginning and end of the trips. Transport for London publishes online all trips made by hire bikes along many other datasets related to bike usage in London. The files are published weekly. They have information on starting and ending stations, exact time of the trips.\nWe can download the files for August 2018 and do some cleaning to map the most used routes in London. We first need to filter for completed trips and select trips with different origins/destinations.\nThe next step is to aggregate the trips by pairs of origin and destination stations. The results should be how many trips have originated and ended from a specific pair in August 2018.\n\n# download the trips taken by hire bikes in August 2018\ndownload.file(\"https://cycling.data.tfl.gov.uk/usage-stats/121JourneyDataExtract01Aug2018-07Aug2018.csv\",\n              destfile = \"data/London/121JourneyDataExtract01Aug2018-07Aug2018.csv\")\ndownload.file(\"https://cycling.data.tfl.gov.uk/usage-stats/122JourneyDataExtract08Aug2018-14Aug2018.csv\",\n              destfile = \"data/London/122JourneyDataExtract08Aug2018-14Aug2018.csv\")\ndownload.file(\"https://cycling.data.tfl.gov.uk/usage-stats/123JourneyDataExtract15Aug2018-21Aug2018.csv\",\n              destfile = \"data/London/123JourneyDataExtract15Aug2018-21Aug2018.csv\")\ndownload.file(\"https://cycling.data.tfl.gov.uk/usage-stats/124JourneyDataExtract22Aug2018-28Aug2018.csv\",\n              destfile = \"data/London/124JourneyDataExtract22Aug2018-28Aug2018.csv\")\n\n# list the cycle hire extracts from TfL \n# https://cycling.data.tfl.gov.uk/\nlibrary(data.table)\nextracts <- list.files(\"data/London\", pattern=glob2rx(\"*Journey*Data*Extract*\"), \n                       recursive = TRUE,\n                       full.names = TRUE)\n\n# loop through files\njourneys <- do.call(\"rbind\", lapply(extracts, fread))\n\n# aggregate at the station day level\njourneys_agg <- journeys %>%\n  filter(!`StartStation Id`==`EndStation Id`) %>% # filter trip with same origin and destination\n  filter(!is.na(`EndStation Id`)) %>% # filter lost bike\n  filter(!is.na(`StartStation Id`)) %>% # filter lost bike\n  filter(`StartStation Id` %in% stations_df$`Station ID`) %>% # filter stations that closed/ were not opened\n  filter(`EndStation Id` %in% stations_df$`Station ID`) %>%  # filter stations that closed/ were not opened\n  filter(!Duration <= 0) %>% # filter no trips and lost\n  filter(Duration <= 180*60) %>%  # filter trips not well docked\n  group_by(`StartStation Id`, `EndStation Id`) %>%\n  summarise(journeys = n(), \n            mean_duration = mean(Duration)) %>%\n  ungroup() %>%\n  mutate(share_trips = 100*journeys/sum(journeys))\n\n# quick stats\nsummary(journeys_agg)\n\n StartStation Id EndStation Id      journeys       mean_duration  \n Min.   :  1.0   Min.   :  1.0   Min.   :  1.000   Min.   :   60  \n 1st Qu.:167.0   1st Qu.:174.0   1st Qu.:  1.000   1st Qu.:  780  \n Median :341.0   Median :350.0   Median :  2.000   Median : 1120  \n Mean   :374.4   Mean   :381.3   Mean   :  4.847   Mean   : 1297  \n 3rd Qu.:581.0   3rd Qu.:592.0   3rd Qu.:  5.000   3rd Qu.: 1530  \n Max.   :833.0   Max.   :833.0   Max.   :679.000   Max.   :10800  \n  share_trips       \n Min.   :0.0001163  \n 1st Qu.:0.0001163  \n Median :0.0002325  \n Mean   :0.0005635  \n 3rd Qu.:0.0005812  \n Max.   :0.0789324  \n\n\nMost origin/destination pairs have 4.8474313 trips during the period. The average duration is 21.6101172 min.\nWe can then filter our journeys to the top 2 percentiles of the trips. Most pairs do not have any trips (none goes from the furthest station in Hackney down to Oval station). Plotting all lines would be messy.\n\nlibrary(stplanr)\n# filter out top 2% \nod_top2 = journeys_agg %>% \n  arrange((journeys)) %>% \n  top_frac(0.02, wt = journeys)\n\n# Creating centroids representing desire line start and end points.\ndesire_lines = od2line(od_top2, stations_df) # here using package stplanr \n\nWe plot the top 0.2% of pairs by the number of trips (you can reduce the percentage if your computer is too slow). We can see that most trips originate from the centre. Let’s try to make it nicer and more interactive:\n\nlibrary(classInt)\nlibrary(tmap)\n# find the breaks\nbrks <- classIntervals(desire_lines$journeys, 5, style = \"jenks\")\n               \n# plot\ntmap_mode(\"view\")\ntm_basemap() + # add a London basemap\ntm_shape(desire_lines) + # add the OD lines\n  tm_lines(id = \"journeys\", # set the pop up id to the number of journeys\n           palette = \"plasma\", # purple to yellow palette\n           breaks = brks$brks, # jenks breaks defined earlier\n           lwd = \"share_trips\", # share trips colour\n           scale = 9,\n           title.lwd = \"Share trips (%)\", # set thickness of lines\n           alpha = 0.3, # transparency\n           col= \"journeys\", # set colour fill to number of journeys\n           title = \"Number of trips\" \n  ) +\n  tm_shape(stations_df) + # add the stations for context\n  tm_symbols(id = \"commonName\", col = \"red\", alpha = 0, scale = .5) + # names of stations as pop up id\n  tm_scale_bar() +\n  tm_layout(\n    legend.bg.alpha = 0.5,\n    legend.bg.color = \"white\") # legend format\n\n\n\n\n\n\nExercise\n\nLook at the documentation for one of the APIs mentioned for data extraction (or another API you are aware of) or the CDRC\nThink of 2 ideas of web maps you could construct from your chosen data. Think about the basemap and data you would plot on top.\n\n\n\n4.2.5 Geocoding API\nBelow is a short exploration of a the geocoding API library(tidygeocoder). In your own time try to use it to automatically embed coordinates between addresses.\n\nlibrary(tidygeocoder)\n\n# Create a dataframe with addresses\nsome_addresses <- tibble::tribble(\n~name,                  ~addr,\n\"South Campus Teaching Hub\",          \"140 Chatham St, Liverpool L7 7BA\",\n\"Sefton Park\", \"Sefton Park, Liverpool L17 1AP\",\n\"Stanley Street\", \"4 Stanley St, Liverpool L1 6AA\"\n)\n\n# Geocode the addresses\nlat_longs <- some_addresses %>%\n  geocode(addr, method = 'osm', lat = latitude , long = longitude)\n\n\n# You could also be reading addressed from a file \nliverpool_addresses <- read_sf(\"data/example_addresses_liverpool.csv\") \n\nlat_longs <- liverpool_addresses %>%\n  geocode(addr, method = 'osm', lat = latitude , long = longitude)\n\nReverse Geocoding\nYou can also reverse geo-code the data, open the output and see what the result is\n\nreverse <- lat_longs %>%\n  reverse_geocode(lat = latitude, long = longitude, method = 'osm',\n                  address = address_found, full_results = TRUE) %>%\n  select(-addr, -licence)\n\nOther packages also do geocoding such as library(ggmap) have a look here"
  },
  {
    "objectID": "apis.html#references",
    "href": "apis.html#references",
    "title": "4  APIs",
    "section": "4.3 References",
    "text": "4.3 References\nArribas-Bel, D. (2014) “Accidental, Open and Everywhere: Emerging Data Sources for the Understanding of Cities”. Applied Geography, 49: 45-53.\nGoodchild, M. F. (2007). Citizens as sensors: the world of volunteered geography. GeoJournal, 69(4), 211-221.\nLazer, D., & Radford, J. (2017). Data ex machina: introduction to big data. Annual Review of Sociology, 43, 19-39.\nLeaflet for R\nTitorchul, O. (2020), Breaking Down Geocoding"
  },
  {
    "objectID": "mapdesign.html#lecture",
    "href": "mapdesign.html#lecture",
    "title": "5  Map design",
    "section": "5.1 Lecture",
    "text": "5.1 Lecture\nSlides can be downloaded here"
  },
  {
    "objectID": "mapdesign.html#lab-designing-maps-with-mapbox-studio-take-out-carto",
    "href": "mapdesign.html#lab-designing-maps-with-mapbox-studio-take-out-carto",
    "title": "5  Map design",
    "section": "5.2 Lab: Designing maps with Mapbox Studio (take out Carto)",
    "text": "5.2 Lab: Designing maps with Mapbox Studio (take out Carto)\nIn this lab, we will put to use some of the ideas and concepts we have learnt about map design. We will do so using Mapbox Studio, a tool that will allow us to control almost any thinkable aspect of a map.\nAs we go through the practicalities, remember the concepts that inspire map design, which we have outlined in the lecture slides. The challenge here is not in learning the software, but in being able to translate abstract notions of design into an applied context.\nTo complete this lab, you will require the following:\n\nThe internet\nAn active Mapbox account Mapbox Studio\n\nMapbox Studio Let’s get starting by logging into our Mapbox account and opening up Mapbox Studio\nYou should see something like this: \nTo explore what is possible, we will create a new style. Click on the “New Style” button and pick the “Monochrome” option. Select the color you prefer. This will load the Studio editor, where we will spend most of this session.\nThe Studio is structured around three main panels: styling on the left, the map canvas, and the toolbar at the top.\n Source: Mapbox"
  },
  {
    "objectID": "mapdesign.html#references",
    "href": "mapdesign.html#references",
    "title": "5  Map design",
    "section": "5.3 References",
    "text": "5.3 References\n\nKatie Jolly’s Map Design Guide\nMapbox’s Guide to Map Design\nThe Mapbox Studio manual\nThe seven deadly sins of visualisation, by James Cheshire\nWes Anderson color palettes\nThe Ship Map, Kiln is a stunning example"
  },
  {
    "objectID": "interact.html#lecture",
    "href": "interact.html#lecture",
    "title": "6  Interactivity",
    "section": "6.1 Lecture",
    "text": "6.1 Lecture\nSlides can be downloaded here"
  },
  {
    "objectID": "interact.html#lab",
    "href": "interact.html#lab",
    "title": "6  Interactivity",
    "section": "6.2 Lab",
    "text": "6.2 Lab\nIn this lab, we are going to get our hands dirty and play with different elements that allow us to make a map interactive. We will do so using Kepler/gl, which makes possible (and even fun!) to work interactivity into a map in different ways.\nAs we go through the hands-on aspect of this block, please keep the lecture slides handy and revisit them as much as you need to. As always, the real challenge is not to learn how to use a piece of software, but how to apply conceptual notions in a practical context.\nTo complete this lab, you will require the following:\n\nThe internet\nKepler.gl\n\n\n6.2.1 Getting to know Kepler.gl\nWe will use Kepler to quickly be able to make web maps and explore how you can build interactivity in web maps.\nLet us start by open up Kepler.gl\nYou should see a dashboard that looks more or less like:\n\nTo start understaning the main features, you can create a “New Map” (either from the dasboard or the “Maps” section, you will be able to find that button), and add the imd2019 dataset we used for Lab 6 (remember, you will find it on the “Shared with you” tab). This will take you to a new page that looks roughly like:\nWe will use some density data you can download here\n\nOnce the dataset has been uploaded, it shows under Layers on the left-hand side panel.\n\nExplore the Kepler.gl interface.\nLet’s walk through the basics of Kepler.gl as a (web) GIS:\n\n\nBasemap: pick your background\nMain layer: focus on style for now\n\nSTYLE: fill colour, outline, radius\nPOP-UP: Tooltips\nLEGEND\n\n\nThere is lots of documentation to help you here.\n\n\n6.2.2 Interactivity\nNow let’s remember the building blocks of interactivity we have learnt in the lecture. We will demonstrate in bold those that we will work through in the lab:\n\nFiltering\n\nPan\nZoom\nSubset\n\nPerspective\nVolume\nTooltips\nSplit\nAnimate\n\nTo demonstrate animations, we will use another dataset we have enountered in the past, the CLIWOC ship logs:\nhttps://figshare.com/articles/CLIWOC_Slim_and_Routes/11941224\nWe will work with individual logs (cliwoc_slim) to create an animation of the logs, for example just showing expeditions between certain date, as in this example of expeditions into the Caribbean.\nVideo\nDate Prep\nFirst we need the data in a geojson format and to make sure that the time variable is in the correct date-time format. For this we will need to rely on QGIS or R.\nIn QGIS there are two steps:\n\nImport the cliwoc_slim.geopackage as save as geojson\n\n\n\nChange the date variable to a date and time variable. If you don’t do this, kepler.gl won’t recognize it as a date.\n\n\nBack to Kepler.gl\n\nOnce this is done you can import that data to Kepler.gl.\nInspect the data, focusing on the columns (attributes).\n\n\n\nCreate a filter by date (or additional filters).\n\n\nNotice the time slider showing on the lower right corner.\n\nExercise\nNow we know the mechanics of interactivity in Kepler.gl, let’s show off! Pick whichever you want first, and have a go at the following maps:\n\nAn animation of global trade over time A map that lets you pick a given country and display its main routes\nA map that lets you identify the vesel ID (id), date, and country of ships around Cape Town\nA choropleth where you can select routes by their length in days\nAn animation of each route in the region around Jakarta\nA map that allows you to select a single route, zoom into its origin, and then pan throughout the route\n\nOnce completed, select the one you like best, and post it on Teams.\nPresentation\n\nYou will then have 30 seconds to present your favorite map and hit the following points:\nWhat the map shows What interactivity element(s) you have used One thing you think is really effective about it\nRemember, 30 seconds. Short and sweet. Make them count!"
  },
  {
    "objectID": "interact.html#references",
    "href": "interact.html#references",
    "title": "6  Interactivity",
    "section": "6.3 References",
    "text": "6.3 References\n\nTamara Munzner’s “Visualization Analysis & Design”. This lecture draws mostly on Chapter 1 (What’s Vis, and Why Do It?).\nAndy Kirk’s “Data Visualisation: a Handbook for Data Driven Design”.\nMapbox’s Guide to Map Design.\nGeo Temporal data visualisation"
  },
  {
    "objectID": "choro.html#lecture",
    "href": "choro.html#lecture",
    "title": "7  Statistical visualisation",
    "section": "7.1 Lecture",
    "text": "7.1 Lecture\nSlides can be downloaded here"
  },
  {
    "objectID": "choro.html#lab",
    "href": "choro.html#lab",
    "title": "7  Statistical visualisation",
    "section": "7.2 Lab:",
    "text": "7.2 Lab:"
  },
  {
    "objectID": "choro.html#references",
    "href": "choro.html#references",
    "title": "7  Statistical visualisation",
    "section": "7.3 References",
    "text": "7.3 References"
  },
  {
    "objectID": "dashboards.html#lecture",
    "href": "dashboards.html#lecture",
    "title": "8  Dashboards",
    "section": "8.1 Lecture",
    "text": "8.1 Lecture\nSlides can be downloaded here"
  },
  {
    "objectID": "dashboards.html#lab",
    "href": "dashboards.html#lab",
    "title": "8  Dashboards",
    "section": "8.2 Lab:",
    "text": "8.2 Lab:"
  },
  {
    "objectID": "dashboards.html#references",
    "href": "dashboards.html#references",
    "title": "8  Dashboards",
    "section": "8.3 References",
    "text": "8.3 References"
  },
  {
    "objectID": "techgallery.html",
    "href": "techgallery.html",
    "title": "9  Technology Gallery",
    "section": "",
    "text": "Dani Arribas-Bel\nLecture: Technology gallery\nLab: Assignment II clinic."
  },
  {
    "objectID": "html/introduction_slides.html",
    "href": "html/introduction_slides.html",
    "title": "10  Web Mapping & Analysis - Introduction",
    "section": "",
    "text": "11\nWeb Mapping & Analysis by Dani Arribas-Bel is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "html/introduction_slides.html#today",
    "href": "html/introduction_slides.html#today",
    "title": "10  Web Mapping & Analysis - Introduction",
    "section": "10.1 Today",
    "text": "10.1 Today\n\nAnatomy of the Web Map\nOverview\nLogistics"
  },
  {
    "objectID": "html/introduction_slides.html#anatomy-of-the-web-map",
    "href": "html/introduction_slides.html#anatomy-of-the-web-map",
    "title": "10  Web Mapping & Analysis - Introduction",
    "section": "10.2 Anatomy of the Web Map",
    "text": "10.2 Anatomy of the Web Map"
  },
  {
    "objectID": "html/introduction_slides.html#section",
    "href": "html/introduction_slides.html#section",
    "title": "10  Web Mapping & Analysis - Introduction",
    "section": "10.3 ",
    "text": "10.3"
  },
  {
    "objectID": "html/introduction_slides.html#section-1",
    "href": "html/introduction_slides.html#section-1",
    "title": "10  Web Mapping & Analysis - Introduction",
    "section": "10.4 ",
    "text": "10.4"
  },
  {
    "objectID": "html/introduction_slides.html#section-2",
    "href": "html/introduction_slides.html#section-2",
    "title": "10  Web Mapping & Analysis - Introduction",
    "section": "10.5 ",
    "text": "10.5"
  },
  {
    "objectID": "html/introduction_slides.html#building-blocks-of-a-web-map",
    "href": "html/introduction_slides.html#building-blocks-of-a-web-map",
    "title": "10  Web Mapping & Analysis - Introduction",
    "section": "10.6 Building blocks of a web map",
    "text": "10.6 Building blocks of a web map\n\n\n(Geo-)Data\nHardware\nSoftware\n(Effective and beautiful) Design"
  },
  {
    "objectID": "html/introduction_slides.html#geo-data",
    "href": "html/introduction_slides.html#geo-data",
    "title": "10  Web Mapping & Analysis - Introduction",
    "section": "10.7 (Geo-)Data",
    "text": "10.7 (Geo-)Data\n\n\n “Data graphics visually display measured quantities by means of the combined use of points, lines, a coordinate system, numbers, symbols, words, shading, and color”\n\n\n The Visual Display of Quantitative Information. Edward R. Tufte"
  },
  {
    "objectID": "html/introduction_slides.html#hardware",
    "href": "html/introduction_slides.html#hardware",
    "title": "10  Web Mapping & Analysis - Introduction",
    "section": "10.8 Hardware",
    "text": "10.8 Hardware"
  },
  {
    "objectID": "html/introduction_slides.html#software",
    "href": "html/introduction_slides.html#software",
    "title": "10  Web Mapping & Analysis - Introduction",
    "section": "10.9 Software",
    "text": "10.9 Software\n\n           \n\nurl"
  },
  {
    "objectID": "html/introduction_slides.html#design",
    "href": "html/introduction_slides.html#design",
    "title": "10  Web Mapping & Analysis - Introduction",
    "section": "10.10 Design",
    "text": "10.10 Design"
  },
  {
    "objectID": "html/introduction_slides.html#overview",
    "href": "html/introduction_slides.html#overview",
    "title": "10  Web Mapping & Analysis - Introduction",
    "section": "10.11 Overview",
    "text": "10.11 Overview"
  },
  {
    "objectID": "html/introduction_slides.html#content",
    "href": "html/introduction_slides.html#content",
    "title": "10  Web Mapping & Analysis - Introduction",
    "section": "10.12 Content",
    "text": "10.12 Content\n - W1 Introduction & Context \n - W2-4: Data Backends \n - W5: Assignment I \n - W6-8: Frontend Topics \n - W9: Dashboards \n - W10: Technology Gallery"
  },
  {
    "objectID": "html/introduction_slides.html#assessment",
    "href": "html/introduction_slides.html#assessment",
    "title": "10  Web Mapping & Analysis - Introduction",
    "section": "10.13 Assessment",
    "text": "10.13 Assessment\n\nTwo pieces of coursework (50%/50%)\nEquivalent to 2,500 words each\nDue on W-6 and W-11\nDescription in lectures + lab clinics"
  },
  {
    "objectID": "html/introduction_slides.html#logistics",
    "href": "html/introduction_slides.html#logistics",
    "title": "10  Web Mapping & Analysis - Introduction",
    "section": "10.14 Logistics",
    "text": "10.14 Logistics"
  },
  {
    "objectID": "html/introduction_slides.html#website",
    "href": "html/introduction_slides.html#website",
    "title": "10  Web Mapping & Analysis - Introduction",
    "section": "10.15 Website",
    "text": "10.15 Website\n\n\n\n\n https://gdsl-ul.github.io/wma/"
  },
  {
    "objectID": "html/introduction_slides.html#lecturelabs",
    "href": "html/introduction_slides.html#lecturelabs",
    "title": "10  Web Mapping & Analysis - Introduction",
    "section": "10.16 Lecture/Labs",
    "text": "10.16 Lecture/Labs\nLectures: Mondays 9-10am @Teams\n - Live streams + video archive \n - Underlying concepts + Context \nLabs: Mondays 10am-12noon @Teams\n - Hands on \n - Interactive"
  },
  {
    "objectID": "html/introduction_slides.html#teams",
    "href": "html/introduction_slides.html#teams",
    "title": "10  Web Mapping & Analysis - Introduction",
    "section": "10.17 Teams",
    "text": "10.17 Teams"
  },
  {
    "objectID": "html/introduction_slides.html#homework",
    "href": "html/introduction_slides.html#homework",
    "title": "10  Web Mapping & Analysis - Introduction",
    "section": "10.18 Homework",
    "text": "10.18 Homework\n\n\nBring at least one example of web mapping that you find compelling\nContribute the link to Teams"
  },
  {
    "objectID": "mapdesign.html#lab-designing-maps-with-mapbox-studio",
    "href": "mapdesign.html#lab-designing-maps-with-mapbox-studio",
    "title": "5  Map design",
    "section": "5.2 Lab: Designing maps with Mapbox Studio",
    "text": "5.2 Lab: Designing maps with Mapbox Studio\nIn this lab, we will put to use some of the ideas and concepts we have learnt about map design. We will do so using Mapbox Studio, a tool that will allow us to control almost any thinkable aspect of a map.\nAs we go through the practicalities, remember the concepts that inspire map design, which we have outlined in the lecture slides. The challenge here is not in learning the software, but in being able to translate abstract notions of design into an applied context.\nTo complete this lab, you will require the following:\n\nThe internet\nAn active Mapbox account Mapbox Studio\n\nMapbox Studio\nLet’s get starting by logging into our Mapbox account and opening up Mapbox Studio\nYou should see something like this: \nTo explore what is possible, we will create a new style. Click on the “New Style” button and pick the “Monochrome” option. Select the color you prefer. This will load the Studio editor, where we will spend most of this session.\nThe Studio is structured around three main panels: styling on the left, the map canvas, and the toolbar at the top.\n\nSource: Mapbox\nMost of the time, we will select views, layers, and data from the styling panel, and our actions will drive changes on the map canvas. In this tutorial, we will examine how to modify and style the different elements of design we have seen in class:\n\nColor\nTexture\nLabelling and typography\nIconography\n\nWe will finish our tour discussing the Elements feature and learning about how to add our own data to the maps we style in Studio.\nExercise\nFor this exercise, we will be using the “CLIWOC Slim and Routes” data product: https://figshare.com/articles/CLIWOC_Slim_and_Routes/11941224\nTeam in groups of two to four and pick one of the following options:\n\nGlobal map of trade routes\nMap of ship activity around South Africa\nMap showing how important the island of Saint Helena was in this period\nMap of shipping activity in the English Channel\nMap of expeditions into the Arctic\nMap of activity around the Caribbean\n\nStyle a map according to its goal.\n\n5.2.1 Bring your mapped style back into R\nGo back to the end of the Lab 3 and use the mapdeck() function to bring your styled map back into R. For more on mapdeck check this page.\n\n\n5.2.2 Presentation\nOnce you are happy with your final style, publish it and drop the link on the module’s Team. Designate one member of the group to present it. The presentation should cover the following:\n\nWhat is the map about?\nWhat design elements did you tweak? How? Why?\nWhat choices did you make following design principles? What other alternatives did you consider? Why did you opt for those choices?"
  }
]