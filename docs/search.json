[
  {
    "objectID": "introduction.html#lecture",
    "href": "introduction.html#lecture",
    "title": "1  Introduction",
    "section": "1.1 Lecture",
    "text": "1.1 Lecture\nSlides can be found here"
  },
  {
    "objectID": "introduction.html#lab-powerful-examples",
    "href": "introduction.html#lab-powerful-examples",
    "title": "1  Introduction",
    "section": "1.2 Lab: Powerful examples",
    "text": "1.2 Lab: Powerful examples\nThis lab has two main components:\n\nThe first one will require you to find a partner and work together with her/him\nAnd the second one will involve group discussion.\n\n\n1.2.1 Paired activity\nIn pairs, find three examples where web maps are used to communicate an idea. Complete the following sheet for each example:\n\nSubstantive\n\nTitle: Title of the map/project\nAuthor: Who is behind the project?\nBig idea: a “one-liner” on what the project tries to accomplish –\nMessage: what does the map try to get accross\n\nTechnical\n\nURL:\nInteractivity: does the map let you interact with it in any way? Yes/No\nZoomable: can you explore the map at different scales? Yes/No\nTooltips:\nBasemap: Is there an underlying map providing geographical context? Yes/No. If so, who is it provided by?\nTechnology: can you guess what technology does this map rely on?\n\n\nPost each sheet as a separate item on the Teams channel for Lab No.1\nAs an example, below is the sheet for the project “WHO Coronavirus (COVID-19) Dashboard” \n\nSubstantive\n\nTitle: WHO Coronavirus (COVID-19) Dashboard\nAuthor: World Health Organization\nBig idea: Shows confirmed COVID-19 cases and deaths by country to date\nMessage: The project displays a map of the world where COVID-19 cases are shown by country. This element is used to show which countries have had more cases (large trends). A drop down button allows us to visualise the map by a) Total per 100,000 population b) % change in the last 7 days c) newly reported in the last 7 days d) newly reported in the last 24 hours.\n\nTechnical\n\nURL: https://covid19.who.int/\nInteractivity: Yes\nZoomable: Yes\nTooltips: Yes\nBasemap: No\nTechnology: Unknown\n\n\nHere are a couple of other COVID-19 examples of web-maps that where basemaps and technology is easier to spot.\n\n“London School of Hygiene & Tropical Medicine - COVID-19 tracker”\n“Tracking Coronavirus in the United Kingdom: Latest Map and Case Count”\n\n\n\n1.2.2 Class discussion\nWe will select a few examples posted and collectively discuss (some of) the following questions:\n\nWhat makes them powerful, what “speaks” to us?\nWhat could be improved, what is counter-intuitive?\nWhat design elements do they rely on?\nWhat technology do they use?"
  },
  {
    "objectID": "introduction.html#references",
    "href": "introduction.html#references",
    "title": "1  Introduction",
    "section": "1.3 References",
    "text": "1.3 References\n\nFor an excellent coverage of “visualisation literacy”, Chapter 11 of Andy Kirk’s “Data Visualisation” is a great start. Lab: Getting up to speed for web mapping\nA comprehensive overview of computational notebooks and how they relate to modern scientific work is available on Ch.1 of the GDS book.\nA recent overview of notebooks in Geography is available in Boeing & Arribas-Bel (2021)"
  },
  {
    "objectID": "structure.html#introduction",
    "href": "structure.html#introduction",
    "title": "Syllabus",
    "section": "Introduction",
    "text": "Introduction\nBlock 1\n\nLecture: Introduction to the module\nLab: Powerful examples"
  },
  {
    "objectID": "structure.html#data-backends",
    "href": "structure.html#data-backends",
    "title": "Syllabus",
    "section": "Data Backends",
    "text": "Data Backends\nBlock 2\n\nLecture: The Web’s architecture and Economy\nLab: What do APIs actually do?\n\nBlock 3\n\nLecture: Data architechtures & formats\nLab: Creating, manipulating, and integrating web geospatial data\n\nBlock 4\n\nLecture: APIs\nLab: Acquiring data from the web"
  },
  {
    "objectID": "structure.html#assignment-i",
    "href": "structure.html#assignment-i",
    "title": "Syllabus",
    "section": "Assignment I",
    "text": "Assignment I\nBlock 5\n\nLecture: Q&A\nLab: Clinic\n\nAssignment I: Combining (geo-)data in an interactive map"
  },
  {
    "objectID": "structure.html#frontend-topics",
    "href": "structure.html#frontend-topics",
    "title": "Syllabus",
    "section": "Frontend Topics",
    "text": "Frontend Topics\nBlock 6\n\nLecture: Map design\nLab: Designing maps with Kepler\n\nBlock 7\n\nLecture: Interactivity\nLab: Designing for interactivity\n\nBlock 8\n\nLecture: Statistical visualisation\nLab: Choropleths in Kepler"
  },
  {
    "objectID": "structure.html#dashboards",
    "href": "structure.html#dashboards",
    "title": "Syllabus",
    "section": "Dashboards",
    "text": "Dashboards\nBlock 9\n\nLecture: Dashboards: bringing analysis to the web\nLab: Building Dashboards (Shiny)\n\nBlock 10\n\nLecture: Technology gallery\nLab: Assignment II clinic\n\nAssignment II: A dashboard of IMD"
  },
  {
    "objectID": "overview.html#aims",
    "href": "overview.html#aims",
    "title": "Overview",
    "section": "Aims",
    "text": "Aims\nThis module aims to:\n\nProvide hands-on experience and training in the design and generation of web-based mapping and geographical information tools.\nProvide hands-on experience and training in the use of software to access, analyse and visualize web-based geographical information."
  },
  {
    "objectID": "overview.html#learning-outcomes",
    "href": "overview.html#learning-outcomes",
    "title": "Overview",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nBy the end of the module, students should be able to:\n\nExperience using tile rendering tools to generate content for map-based web sites.\nKnowledge of web based mapping infrastructure\nWeb-based data collection techniques (accessing Twitter, Facebook, Google and OpenStreetmap information)\nNetwork analysis\nProgramming skills to enable basic online data manipulation and web mapping"
  },
  {
    "objectID": "overview.html#feedback",
    "href": "overview.html#feedback",
    "title": "Overview",
    "section": "Feedback",
    "text": "Feedback\nFormal assessment. Two pieces of coursework (50%/50%). Equivalent to 2,500 words each\nVerbal face-to-face feedback. Immediate face-to-face feedback will be provided during computer, discussion and clinic sessions in interaction with staff. This will take place in all live sessions during the semester.\nTeams Forum. Asynchronous written feedback will be provided via Teams. Students are encouraged to contribute by asking and answering questions relating to the module content. Staff will monitor the forum Monday to Friday 9am-5pm, but it will be open to students to make contributions at all times. Response time will vary depending on the complexity of the question and staff availability."
  },
  {
    "objectID": "overview.html#computational-environment",
    "href": "overview.html#computational-environment",
    "title": "Overview",
    "section": "Computational Environment",
    "text": "Computational Environment\nThis course can be followed by anyone with access to a bit of technical infrastructure. This section details the set of local and online requirements you will need to be able to follow along, as well as instructions or pointers to get set up on your own. This is a centralized section that lists everything you will require, but keep in mind that different blocks do not always require everything all the time.\nTo reproduce the code in the book, you need the most recent version of R and packages. These can be installed following the instructions provided in our R installation guide.\n\nSoftware\nTo run the analysis and reproduce the code, you need the following software:\n\nQGIS- the stable version (3.22 LTR at the time of writing) is OK, any more recent version will also work.\nR-4.2.2\nRStudio 2022.12.0-353\nQuarto 1.2.280\nthe list of libraries in the next section\n\nTo install and update:\n\nQGIS, download the appropriate version from QGIS.org\nR, download the appropriate version from The Comprehensive R Archive Network (CRAN)\nRStudio, download the appropriate version from Posit\nQuarto, download the appropriate version from the Quarto website\n\nTo check your version of:\n\nR and libraries run sessionInfo()\nRStudio click help on the menu bar and then About\nQuarto check the version file in the quarto folder on your computer.\n\n\n\nR List of libraries\nThe list of libraries used in this book is provided below:\n\nsf\ngeojsonsf\nmapview\ntidyverse\nviridis\nviridisLite\nhttr\njsonlite\n\nYou need to ensure you have installed the list of libraries used in this book, running the following code:\n\nlist.of.packages.cran <- c( “tidyverse”, “viridis”, “viridisLite”, “ggthemes”, “patchwork”, “showtext”, “RColorBrewer”, “lubridate”, “tmap”, “sjPlot”, “sf”, “sp”, “kableExtra”)\n\n\nnew.packages.cran <- list.of.packages.cran[!(list.of.packages.cran %in% installed.packages()[,“Package”])] if(length(new.packages.cran)) install.packages(new.packages.cran)\n\n\nfor(i in 1:length(list.of.packages.cran)) { library(list.of.packages.cran[i], character.only = T) }\n\n\n\nOnline accounts\n\nCDRC Data: we will use some of the data provided by the CDRC, so a (free) account with them will be necessary.\nMapbox: Mapbox is one of the industry leaders in web mapping. Their free tier is rather generous so will more than suffice for what we will do within the course. You can sign up for a new (free) account here.\nKepler: is a data agnostic, WebGL empowered, high-performance web application for geospatial analytic visualizations."
  },
  {
    "objectID": "assess.html#assignment-i",
    "href": "assess.html#assignment-i",
    "title": "Assessments",
    "section": "Assignment I",
    "text": "Assignment I\n\nTitle: Combining (geo-)data in an interactive map\nType: Coursework\nDue date: Thursday March 2nd, Week 5\n50% of the final mark\nChance to be reassessed\nElectronic submission only\n\nIn this assessment, you will have the opportunity to explore different sources and combine them in a single tileset that can be explored interactively through a web browser. The assignment aims to evaluate your knowledge and aptitude in the following areas:\n\nUnderstanding of core “backend” concepts in web mapping such as tilesets, client-server architecture, or APIs.\nAbility to use the web as a resource for original data.\nDesign skills to present effectively a diverse set of geospatial data in a web map.\n\n\nDesign, data and assemblage.\nThis assignment requires you to source data from the web in different formats, assemble them into a tileset, and document the process. To be successful, you will need to demonstrate your understanding not only of the technical aspects involved in the process, but also of the conceptual notions that underpin them. Below are described the required components for your submission.\nFirst, the design. Start by designing a map for an area you are interested in. There are no clear restrictions but, to ensure you are on the right path, check on your ideas with the module leader, who will be able to assess whether potential problems may arise from your choices. This stage should draw some inspiration from the first weeks of the course, where we looked for examples of web maps and spent time discussing what made them good and why.\nSecond, the data. Draft a list of potential data that would be ideal to use for your map, and try to find out whether they exist and are available. This will be a good guide for which data you will actually end up using. Do not worry about spending a significant amount of time on this aspect; identifying good data takes time and is at the core of this task. Make sure you include both data you can access from direct downloads (e.g. CDRC) and those you download through an API. Once you know which datasets you need, go ahead and do the work required to download them for the map you want to build.\nThird, the assemblage. With all data you have at your disposal from the previous stage, create a tileset that allows to embed the map in an HTML file and explore it through the browser. Pay attention to the design aspects involved in this step too. For example, what is the extent of your map (not necessarily the extent of each of your data)? What are the zoom levels your map will allow? Do you have the same “map” for every zoom level? These are questions you will have to ask (and answer!) yourself to complete this stage successfully.\n\n\nPresentation of your work\nOnce you have created your map, you will need to present it. An important aspect of this stage is that it is not really the map you need to present, but the process of creation you have followed and the design choices you have made that should go into the text. Additionally, you will need to provide evidence that you understand the concepts behind some of the technologies you have used. Write up to 1,000 words and include the following:\n\nMap brief\n\nAbout 250 words introducing the map. This should cover what it tries to represent (what is it about?) and the choices you have made along the way to take that idea into fruition.\nAbout 250 words discussing and motivating the sources of data you have used. Here you should engage not only with what data you are using but why and what they bring to the map. Everything should be in the map for a reason, make sure to spell it out clearly.\n\nConceptual background\n\nAbout 250 words with your description of what an API is, how it works and how it has made your map possible.\nAbout 250 words with your description of how tile-based maps work.\n\n\n\n\nSubmit\nOnce completed, you will need to submit the following:\n\nA static HTML version of an R-markdown that includes two parts:\n\nAll your narrative about the map brief and conceptual background.\nA second section with any code you may have used to complete the assignment, documented in detail. NOTE: this section will not contribute towards the word count.\n\nA compressed .zip file containing you tileset and a HTML file that allows a user to browse through the tileset.\n\nThe assignment will be evaluated based on four main pillars, on which you will have to be successful to achieve a good mark:\n\nMap design abilities. This includes ideas that were discussed in the course in Blocks 1 and 2.\nTechnical skills. This includes your ability to master technologies that allow you to create a compelling map, but also to access interesting and sophiticated data sources.\nOverall narrative. This assesses your aptitude to introduce, motivate and justify your map, as well as you ability to bring each component of the assignment into a coherent whole that “fits together”.\nConceptual understanding of key technologies presented in the course, in particular of APIs and tile-based mapping.\n\n\n\nHow is this assignment useful?\nThis assessment includes several elements that will help you improve critical aspects of your web mapping skills:\nDesign: this is not about making maps, this is about making good maps. And behind every good map there is a set of conscious choices that you will have to think throug to be successful (what map? what data? how to present the data? etc.). Technology: at the end of the day, building good web maps requires solid understanding of current technology that goes beyond what the average person can be expected to know. In this assignment, you will need to demonstrate you are proficient in a series of tasks manipulating geospatial data in a web environment. Presentation: in many real-world contexts, your work is as good as it can come across to the audience it is intended to. This means that it is vital to be able to communicate not only what you are doing but why and on what building blocks it is based on."
  },
  {
    "objectID": "assess.html#assignment-ii",
    "href": "assess.html#assignment-ii",
    "title": "Assessments",
    "section": "Assignment II",
    "text": "Assignment II\n\nTitle: A dashboard of IMD\nType: Coursework\nDue date: Thursday April 27th, Week 10\n50% of the final mark\nChance to be reassessed\nElectronic submission only\n\nThis assignment requires you to build a dashboard for the Index of Multiple Deprivation. To be successful, you will need to demonstrate your understanding not only of technical elements, but of the design process required to create a product that can communicate complex ideas effectively. There are three core building blocks you will have to assemble to build your dashboard: basemap, main map(s), and widgets. Let us explore each of them more in detail.\nFirst, the basemap. Design your own basemap using Mapbox. Think about the data in the background, which colors, the zoom levels that will be allowed, and how it all comes together to create a backdrop for your main message that is conducent to the experience you want to create. The basemap is like a good side dish: it’s there to make you like the main course even more.\nSecond, the main map(s). One you have your own basemap from Mapbox… move to R. This is where the core of your dashboard should come to shine. What you want to show, how, which interactive elements you will allow the user to access and how they will let them modify the experience of your dashboard. The main course of the meal, make it count!\nThird, additional widgets. One of the advantages of dashboards in comparison to standard web maps is that they allow to bring elements of analysis to a more finished product. Think about what you want your users to be able to analyse, why, and how that will modify the main map. This is the icing on the cake!\n\nSubmit\nOnce completed, you will submit a report through Turnitin that includes the following:\n\nA link to the published dashboard, which needs to be reachable online\nAbout 250 words for the overall idea of the dashboard. What do you want to communicate? What is the story you want to tell?\nAbout 250 words for the data used. Which datasets are you using? Why? What new information do they bring and how they complement each other?\nAbout 250 words to describe your design choices in the basemap and other layers presented (e.g. choropleths).\nAbout 250 words to describe your design choices around interactivity, including both cartographic elements (e.g. zooming, panning) as well as additional interactivity built around components such as widgets.\n\nThe assignment will be evaluated based on:\n\nOverall design of the experience. It is very important you think through every step of preparing this assignment as if it was part of something bigger towards which it contributes. Because that is exactly what it is. Everything should have a reason to be there, and every aspect of the dashboard should be connected to each other following a common thread. And, of course, make this connection and holistic approach come alive in your report.\n(Base)map design. Critically introduce every aspect you have thought about when designing the maps, and explicitly connect it to the overal aim of the dashboard. Be clear in your descriptions and critical in how you engage every design choice.\nInteractivity design. Your dashboard should use interactivity when necessary to deliver a more compelling and fuller experience that better gets your message across. Be sure to clearly lay out in your report which elements are used and why.\nNarrative around the description of the process. Finally, the final mark will also take into account not only how good your dashboard is, but how well you are able to introduce it. Start with the key goals, and then unpack every element in an integrated and compelling way.\n\n\n\nHow is this assignment useful?\nThis assignment combines several elements that will help you improve critical aspects of web mapping:\n\nDesign: this is not about making maps, this is about making good maps. And behind every good map there is a set of conscious choices that you will have to think throug to be successful (what map? what data? how to present the data? etc.).\nTechnology: at the end of the day, building good web maps requires familiarity with the state-of-the-art in terms of web mapping tools. In this assignment, you will need to demonstrate your mastering of some of the key tools that are leading both industry and academia.\nPresentation: in many real-world contexts, your work is as good as it can come across to the audience it is intended to. This means that it is vital to be able to communicate not only what you are doing but why and on what building blocks it is based on."
  },
  {
    "objectID": "assess.html#marking-criteria",
    "href": "assess.html#marking-criteria",
    "title": "Assessments",
    "section": "Marking Criteria",
    "text": "Marking Criteria\nThis course follows the standard marking criteria (the general ones and those relating to GIS assignments in particular) set by the School of Environmental Sciences. Please make sure to check the student handbook and familiarise with them. In addition to these generic criteria, the following specific criteria will be used in cases where computer code is part of the work being assessed:\n\n0-15: the code does not run and there is no documentation to follow it.\n16-39: the code does not run, or runs but it does not produce the expected outcome. There is some documentation explaining its logic.\n40-49: the code runs and produces the expected output. There is some documentation explaining its logic.\n50-59: the code runs and produces the expected output. There is extensive documentation explaining its logic.\n60-69: the code runs and produces the expected output. There is extensive documentation, properly formatted, explaining its logic.\n70-79: all as above, plus the code design includes clear evidence of skills presented in advanced sections of the course (e.g. custom methods, list comprehensions, etc.).\n80-100: all as above, plus the code contains novel contributions that extend/improve the functionality the student was provided with (e.g. algorithm optimizations, novel methods to perform the task, etc.)."
  },
  {
    "objectID": "webarch.html#lecture",
    "href": "webarch.html#lecture",
    "title": "2  Web architecture",
    "section": "2.1 Lecture",
    "text": "2.1 Lecture\nSlides can be downloaded here"
  },
  {
    "objectID": "webarch.html#lab-what-do-apis-actually-do",
    "href": "webarch.html#lab-what-do-apis-actually-do",
    "title": "2  Web architecture",
    "section": "2.2 Lab: What do APIs actually do?",
    "text": "2.2 Lab: What do APIs actually do?\nIn this lab, we will unpack how Application Programming Interfaces (“APIs”) work and we cover the basics of accessing an API using R. Instead of downloading a data set, APIs allow programmers, statisticians (or students) to request data directly from a server to a local machine. When you work with web APIs, two different computers — a client and server — will interact with each other to request and provide data, respectively.\n\n2.2.1 RESTful Web APIs are all around you.\nWeb APIs\n\nAllow you query a remote database over the internet\nTake on a variety of formats\nAdhere to a particular style known as Representation State Transfer or REST (in most cases)\nRESTful APIs are convenient because we use them to query database using URLs\n\nConsider a simple Google search:\n\nEver wonder what all that extra stuff in the address bar was all about? In this case, the full address is Google’s way of sending a query to its databases requesting information related to the search term liverpool top attractions.\n\nIn fact, it looks like Google makes its query by taking the search terms, separating each of them with a +, and appending them to the link https://www.google.com/#q=. Therefore, we should be able to actually change our Google search by adding some terms to the URL:\n\nLearning how to use RESTful APIs is all about learning how to format these URLs so that you can get the response you want.\n\n\n2.2.2 Group activity\nGet into groups of 5 or 6 students. Using your friend the internet, look up answers to the following questions. Each group will be assigned one question and asked to present their findings in 5 min to discuss with the entire class.\n\nWhat is a URL and how can it help us query data? What is a response status and what are the possible categories?\nWhat is a GET request? How does a GET request work?\nWhat are API keys and how do you obtain them? What kinds of restrictions to they impose on users? Find an example of an API key, what does it look like?\n(For 2 groups) More and more APIs pop up every day. Do a bit of quick research and find 2 different examples of APIs that you would be interested in using. 2 groups, 2 or 3 APIs each.\n\n\n\n2.2.3 API R libraries\nThere are two ways to collect data through APIs in R:\nPlug-n-play packages. Many common APIs are available through user-written R Packages. These packages offer functions that conveniently “wrap” API queries and format the response. These packages are usually much more convenient than writing our own query, so it is worth searching for a package that works with the API we need.\nWriting our own API request. If no wrapper function is available, we have to write our own API request and format the response ourselves using R. This is tricky, but definitely doable.\n\n2.2.3.1 tidycensus pair activity\nSome R packages “wrap” API queries and format the response. Lucky us! In pairs, let’s have a look at tidycensus. You can also have a look at the different APIs available from the United States Census Bureau.\ntidycensus is\n- R package first released in mid-2017\n- Allows R users to obtain decennial Census and ACS data pre-formatted for use with with tidyverse tools (dplyr, ggplot2, etc.)\n- Optionally returns geographic data as simple feature geometry for common Census geographies\nCreate a new R-markdown and save it to something you’ll remember, like web_mapping_lab_02.Rmd. To get started working, load the package along with the tidyverse and plyr packages, and set you Census API key. A key can be obtained from http://api.census.gov/data/key_signup.html.\n\nlibrary(plyr)\nlibrary(tidycensus)\nlibrary(tidyverse)\n\ncensus_api_key(\"12efa59339e5a00a910f77f2e691309ae70e1d1b\") #replace this with your key\n\n\nVariables in tidycensus are identified by their Census ID, e.g. B19013_001\nEntire tables of variables can be requested with the table argument, e.g. table = “B19001”\nUsers can request multiple variables at a time, and set custom names with a named vector\n\nSearching for variables Getting variables from the US American Community Survey (ACS) 5-Year Data (2016-2020) requires knowing the variable ID - and there are thousands of these IDs across the different files. To rapidly search for variables, use the load_variables() function. The function takes two required arguments: the year of the Census or endyear of the ACS sample, and the dataset name, which varies in availability by year. For the ACS, use either “acs1” or “acs5” for the ACS detailed tables, and append /profile for the Data Profile and /subject for the Subject Tables. To browse these variables, assign the result of this function to a variable and use the View function in RStudio. An optional argument cache = TRUE will cache the dataset on your computer for future use.\n\nview_vars <- load_variables(2020, \"acs5\", cache = TRUE)\n\nview(view_vars)\n\nEXERCISE - In your pairs explore some of the different variables available in the 5-Year ACS (2016-2020). Make a note of 3 variables you would be interested in exploring. The ACS2 variables page might also help.\n\nincome <- get_acs(geography = \"state\", table = \"B19001\") #getting income data by state\nincome\n\n# A tibble: 884 × 5\n   GEOID NAME    variable   estimate   moe\n   <chr> <chr>   <chr>         <dbl> <dbl>\n 1 01    Alabama B19001_001  1888504  5749\n 2 01    Alabama B19001_002   153635  2979\n 3 01    Alabama B19001_003   105415  2397\n 4 01    Alabama B19001_004   106327  2522\n 5 01    Alabama B19001_005   100073  2674\n 6 01    Alabama B19001_006   100569  3023\n 7 01    Alabama B19001_007    96815  2745\n 8 01    Alabama B19001_008    87120  2491\n 9 01    Alabama B19001_009    86181  2124\n10 01    Alabama B19001_010    75721  2512\n# … with 874 more rows\n\n\nEXERCISE - 1) What is a tibble? 2) Discuss the format of the data obtained with your partner and then use the function get_acs to explore the 3 variables you discussed in the previous exercise.\nYou can also get “wide” census data:\n\ninc_wide <- get_acs(geography = \"state\", table = \"B19001\", output = \"wide\")\ninc_wide\n\n# A tibble: 52 × 36\n   GEOID NAME    B1900…¹ B1900…² B1900…³ B1900…⁴ B1900…⁵ B1900…⁶ B1900…⁷ B1900…⁸\n   <chr> <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 42    Pennsy…  5.11e6    8064  296733    3893  206216    3771  223380    3598\n 2 06    Califo…  1.31e7   18542  614887    6699  507398    5286  435382    5251\n 3 54    West V…  7.34e5    2810   62341    2318   43003    1497   45613    1648\n 4 49    Utah     1.00e6    2384   36211    1536   27395    1378   28460    1507\n 5 36    New Yo…  7.42e6   12559  471680    6161  340614    4703  303901    4201\n 6 11    Distri…  2.88e5    1319   24083    1442   11315     809    8300     842\n 7 02    Alaska   2.55e5    1326    9818     613    7476     651    8007     633\n 8 12    Florida  7.93e6   23200  494959    6755  329848    4816  354967    5030\n 9 45    South …  1.96e6    5748  144667    3397   93868    2582   94132    2606\n10 38    North …  3.21e5    1737   18120     846   12664     795   12611     874\n# … with 42 more rows, 26 more variables: B19001_005E <dbl>, B19001_005M <dbl>,\n#   B19001_006E <dbl>, B19001_006M <dbl>, B19001_007E <dbl>, B19001_007M <dbl>,\n#   B19001_008E <dbl>, B19001_008M <dbl>, B19001_009E <dbl>, B19001_009M <dbl>,\n#   B19001_010E <dbl>, B19001_010M <dbl>, B19001_011E <dbl>, B19001_011M <dbl>,\n#   B19001_012E <dbl>, B19001_012M <dbl>, B19001_013E <dbl>, B19001_013M <dbl>,\n#   B19001_014E <dbl>, B19001_014M <dbl>, B19001_015E <dbl>, B19001_015M <dbl>,\n#   B19001_016E <dbl>, B19001_016M <dbl>, B19001_017E <dbl>, …\n\n\nLet’s make our query a bit more precise. We are going to query data on median household income and median age by county in the state of New York from the 2016-2020 ACS.\n\nga_wide <- get_acs(\n  geography = \"county\",\n  state = \"Louisiana\",\n  variables = c(medinc = \"B19013_001\",\n                medage = \"B01002_001\"),\n  output = \"wide\",\n  year = 2020\n)\n\nLet’s plot one of our variables. By default, ggplot organizes the data into 30 bins; this option can be changed with the bins parameter.\n\nggplot(ga_wide, aes(x = medincE)) + \n  geom_histogram(bins = 15) #argument bins = 15 in our call to geom_histogram()\n\n\n\n\nWe can also easily explort correlations between variables. The geom_point() function, which plots points on a chart relative to X and Y values for observations in a dataset. This requires specification of two columns in the call to aes().\n\nggplot(ga_wide, aes(x = medageE, y = medincE)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\nEXERCISE - In your pairs, modify the state, vairables and year parametres in your get_acs function and produce some other simple scatter plots (cloud of points) that suggest correlations between your variables of interest.\nYou can also directly map data you have queried in tidycensus. We will look at this in future sessions. For a complete overview of tidycensus please see Analyzing US Census Data: Methods, Maps, and Models in R.\n\n\n2.2.3.2 Your own API request demo\nThe R libraries that are often used for APIs are httr and jsonlite. They serve different roles in our introduction of APIs, but both are essential.\nJSON stands for JavaScript Object Notation. While JavaScript is another programming language. JSON is useful because it is easily readable by a computer, and for this reason, it has become the primary way that data is transported through APIs. Most APIs will send their responses in JSON format. Using the jsonlite package, you can extract and format data into an R dataframe. JSON is a structure formatted with a key (for example, a variable name id) and a value (BikePoints_308). We used the function fromJSON to transform the API request content into a useable dataframe.\nWe will request the locations of all the hire bike stations in London from the Transport for London API. We use the GET function from httr package.The GET() function requires a URL, which specifies the server’s address to which the request needs to be sent.\n\nlibrary(httr)\nlibrary(jsonlite)\n\n#key <- \"YOURKEY HERE\"\nrequest <- GET(\"https://api.tfl.gov.uk/BikePoint/\") # Here we request all the bike docking stations from the Transport for London API\n\n\nrequest # Examine output\n\nResponse [https://api.tfl.gov.uk/BikePoint/]\n  Date: 2023-01-27 11:26\n  Status: 200\n  Content-Type: application/json; charset=utf-8\n  Size: 2.16 MB\n\n\n\nrequest$status_code # The response status is 200 for a successful request\n\n[1] 200\n\n\nMost GET request URLs for API querying have three or four components:\n\nAuthentication Key/Token: A user-specific character string appended to a base URL telling the server who is making the query; allows servers to efficiently manage database access.\nBase URL: A link stub that will be at the beginning of all calls to a given API; points the server to the location of an entire database.\nSearch Parameters: A character string appended to a base URL that tells the server what to extract from the database; basically a series of filters used to point to specific parts of a database.\nResponse Format: A character string indicating how the response should be formatted; usually one of .csv, .json, or .xml.\n\n\nbikepoints <- jsonlite::fromJSON(content(request, \"text\")) # extract the dataframe\nnames(bikepoints) # Print the column names\n\n [1] \"$type\"                \"id\"                   \"url\"                 \n [4] \"commonName\"           \"placeType\"            \"additionalProperties\"\n [7] \"children\"             \"childrenUrls\"         \"lat\"                 \n[10] \"lon\"                 \n\nbikepoints$`Station ID` = as.numeric(substr(bikepoints$id, nchar(\"BikePoints_\")+1, nchar(bikepoints$id))) # create new ID\n\nAfter Block 3 Data architectures we will have revised spatial data forms and you will easily be able to map data that you have obtained through this API.\n\n## Create an sf object from longitude latitude\nlibrary(dplyr)\nlibrary(sf)\nlibrary(tmap)\n# create a sf object\nstations_df <- bikepoints %>% \n  sf::st_as_sf(coords = c(10,9))  %>%  # create pts from coordinates\n  st_set_crs(4326) %>%  # set the original CRS\n  relocate(`Station ID`) # set ID as the first column of the dataframe\n\n# plot bikepoints on a background map for more context\ntmap_mode(\"view\")\ntm_basemap() +\n  tm_shape(stations_df) +\n  tm_symbols(id = \"commonName\", col = \"red\", scale = .5)"
  },
  {
    "objectID": "webarch.html#group-activity-answers",
    "href": "webarch.html#group-activity-answers",
    "title": "2  Web architecture",
    "section": "2.3 Group activity answers",
    "text": "2.3 Group activity answers\n\nUniform Resource Location (URL) is a string of characters that, when interpreted via the Hypertext Transfer Protocol (HTTP). URLs point to a data resource, notably files written in Hypertext Markup Language (HTML) or a subset of a database\n\n1xx informational response - the request was received, continuing process\n2xx successful - the request was successfully received, understood, and accepted\n3xx redirection - further action needs to be taken in order to complete the request\n4xx client error - the request contains bad syntax or cannot be fulfilled\n5xx server error - the server failed to fulfil an apparently valid request\n\nGET requests a representation of a data resource corresponding to a particular URL. The process of executing the GET method is often referred to as a GET request and is the main method used for querying RESTful databases. HEAD, POST, PUT, DELETE: other common methods, though mostly never used for database querying.\nSurfing the web is basically equivalent to sending a bunch of GET requests to different servers and asking for different files written in HTML. Suppose, for instance, I wanted to look something up on Wikipedia. Your first step would be to open your web browser and type in http://www.wikipedia.org. Once you hit return, you would see the page below. Several different processes occured, however, between you hitting “return” and the page finally being rendered:\n\nThe web browser took the entered character string, used the command-line tool “Curl” to write a properly formatted HTTP GET request, and submitted it to the server that hosts the Wikipedia homepage.\nAfter receiving this request, the server sent an HTTP response, from which Curl extracted the HTML code for the page (partially shown below).\nThe raw HTML code was parsed and then executed by the web browser, rendering the page as seen in the window.\nMost APIs requires a key or other user credentials before you can query their database. Getting credentialised with a API requires that you register with the organization. Once you have successfully registered, you will be assigned one or more keys, tokens, or other credentials that must be supplied to the server as part of any API call you make. To make sure users are not abusing their data access privileges (e.g., by making many rapid queries), each set of keys will be given rate limits governing the total number of calls that can be made over certain intervals of time.\n\nMost APIs requires a key before you can query their database. This usually requires you to register with the organization. Most APIs are set up for developers, so you will likely be asked to register an “application.” All this really entails is coming up with a name for your app/bot/project and providing your real name, organization, and email. Note that some more popular APIs (e.g., Twitter, Facebook) will require additional information, such as a web address or mobile number. Once you have registered, you will be assigned one or more keys, tokens, or other credentials that must be supplied to the server as part of any API call you make. Most API keys limits he total number of calls that can be made over certain intervals of time. This is so users do not busing their data access privileges."
  },
  {
    "objectID": "webarch.html#references",
    "href": "webarch.html#references",
    "title": "2  Web architecture",
    "section": "2.4 References",
    "text": "2.4 References\n\nBrief History of the Internet, by the Internet Society, is a handy (and free!) introduction to how it all came to be.\nHaklay, M., Singleton, A., Parker, C. 2008. “Web Mapping 2.0: The Neogeography of the GeoWeb”. Geography Compass, 2(6):2011–2039\nA blog post from Joe Morrison commenting on the recent change of licensing for some of the core software from Mapbox\nTerman, R., 2020. Computational Tools for Social Science\nWalker, K. Analyzing US Census Data: Methods, Maps, and Models in R."
  },
  {
    "objectID": "dataarch.html#lecture",
    "href": "dataarch.html#lecture",
    "title": "3  Data architectures",
    "section": "3.1 Lecture",
    "text": "3.1 Lecture\nSlides can be downloaded here"
  },
  {
    "objectID": "dataarch.html#lab-creating-manipulating-and-integrating-web-geo-spatial-data",
    "href": "dataarch.html#lab-creating-manipulating-and-integrating-web-geo-spatial-data",
    "title": "3  Data architectures",
    "section": "3.2 Lab: Creating, manipulating, and integrating web geo-spatial data",
    "text": "3.2 Lab: Creating, manipulating, and integrating web geo-spatial data\nIn this lab, we will explore and familiarise with some of the most common data formats for web mapping: GeoJSON and Mbtiles. To follow this session, you will need to be able to access the following:\n\nThe internet\nQGIS. Any version should work in this context, but if you are installing it on your computer, QGIS 3.22 is recommended\nThe R libraries listed in the computational environment setup of the course.\n\n\n3.2.1 GeoJSON\nTo get familiar with the format, we will start by creating a GeoJSON file from scratch. Head over to the following website:\nhttps://geojson.io/\nIn there, we will create together a small example to better understand the building blocks of this file format.\n\n\n\ngeojson.io\n\n\nWe will pay special attention to the following aspects:\n\nReadability\nCoordinate system\nAbility to add non-spatial information attached to each record\nHow to save it as a file\n\nEXERCISE\nCreate a GeoJSON file for the following data and save them to separate files:\n\nYour five favorite spots in Liverpool\nA polygon of what you consider to be the boundary of the neighbourhood where you live and the city centre of Liverpool. Name each.\nA route that captures one of your favorite walks around the Liverpool region\n\nIf you are comfortable, upload the files to Microsoft Teams to share them with peers.\n\n\n3.2.2 GeoJSON in R\nWith the files from the exercise at hand, we will then learn how to open them in R-markdown. Create a new R-markdown and save it to something you’ll remember, like web_mapping_lab_03.Rmd.\nThen let’s start by calling the libraries sf and geojsonsf :\n\nlibrary(sf) #simple features, a standardized way to encode spatial vector data\nlibrary(geojsonsf) #converts Between GeoJSON and simple feature objects\n\nNow, place the .geojson files you have created in the same folder where you are storing the R-markdown, or somewhere reachable. For this example, we will assume that the file is called map.geojson and it is stored in the data folder, accessible from the same location where the notebook is. We can read the file as:\n\nliverpool <- geojson_sf(\"data/map.geojson\")\n\nWe can inspect the file to see what it contains:\n\nhead(liverpool)\n\nSimple feature collection with 4 features and 0 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -2.977367 ymin: 53.39987 xmax: -2.954183 ymax: 53.40753\nGeodetic CRS:  WGS 84\n                        geometry\n1 POLYGON ((-2.965248 53.4016...\n2 LINESTRING (-2.975764 53.40...\n3     POINT (-2.977367 53.40753)\n4 POLYGON ((-2.958036 53.4009...\n\n\nIf you are familiar with sf objects, this is exactly it, read straight from a GeoJSON file (if you need a refresher, you can check out introduction to sf) in the Spatial Data Science book.\n A point is single point geometry: POINT (5 2)\n A line string is a sequence of points with a straight line connecting the points: LINESTRING (1 5, 4 4, 4 1, 2 2, 3 2)\n A polygon is a sequence of points that form a closed ring without intersection. Closed means that the first and the last point of a polygon have the same coordinates: POLYGON ((1 5, 2 2, 4 1, 4 4, 1 5))\nLet’s quickly plot the sf object to visualise it in R.\n\nlibrary(mapview) # provides functions to very quickly and conveniently create interactive visualisations of spatial data.\nmapview(liverpool)\n\n\n\n\n\n\nOnce read, the geojson behaves exactly like any sf objects, we can therefore operate on it and tap into the functionality from sf. For example, we can inspect the Coordinate Reference System (CRS) in which it is expressed:\n\nst_crs(liverpool)\n\nCoordinate Reference System:\n  User input: 4326 \n  wkt:\nGEOGCS[\"WGS 84\",\n      DATUM[\"WGS_1984\",\n        SPHEROID[\"WGS 84\",6378137,298.257223563,\n          AUTHORITY[\"EPSG\",\"7030\"]],\n        AUTHORITY[\"EPSG\",\"6326\"]],\n      PRIMEM[\"Greenwich\",0,\n        AUTHORITY[\"EPSG\",\"8901\"]],\n      UNIT[\"degree\",0.0174532925199433,\n        AUTHORITY[\"EPSG\",\"9122\"]],\n      AXIS[\"Latitude\",NORTH],\n      AXIS[\"Longitude\",EAST],\n    AUTHORITY[\"EPSG\",\"4326\"]]\n\n\nUsing some of sf’s functionality. We can reproject it to express it in metres:\n\nliverpool_bng <- st_transform(liverpool, st_crs(27700)) # transform to British National Grid\n\nWhen we inspected our geojson with head(liverpool) we noted that the spatial data is stored in the following format: POINT (-2.977367 53.40753). This is called “well known text” (wkt) and is a representation that spatial databases like PostGIS use as well. Another way to store spatial data as text for storage or transfer, less (human) readable but more efficient is the “well known blurb” (wkb):\n\nlibrary(wkb) #Convert Between Spatial Objects and Well-Known Binary Geometry\n\n#select just polygons\n#liverpool_wkb <- writeWKB(liverpool) #Converts Spatial objects to well-known binary (WKB) geometry representations.\n\nBut the underlying data (point coordinates) can also be extracted directly within R. If we want to pull out the x coordinate for each point, we can access it under geometry.x:\nAnother benefit of reading data with sf is we can use its analytical capabilities. For example, we can calculate the length of line:\n\n#st_length(x, ...)\n\nGiven the the line is expressed in metres (check out EPSG:27700), we can conclude the line spans about 88m.\nOnce we are happy with the data as we will hypothetically need it, we can write it out to any other file format supported in sf. For example, we can create a Geopackge file with the same information:\nThe file name is taken as the data source name. The default for the layer name is the basename (filename without path) of the the data source name. For this, st_write needs to guess the driver. The above command is, for instance, equivalent to:\n\nst_write(liverpool_bng, dsn = \"data/test.gpkg\", layer = \"data/test.gpkg\", driver = \"GPKG\", delete_dsn = TRUE)\n\nDeleting source `data/test.gpkg' using driver `GPKG'\nWriting layer `data/test.gpkg' to data source `data/test.gpkg' using driver `GPKG'\nWriting 4 features with 0 fields and geometry type Unknown (any).\n\n## Writing layer `liverpool_bng' to data source `test.gpkg' using driver `Geopackge'\n\nR’s sf cheatsheet is a good reference for manipulation operations/spatial predicates with simple features.\nEXERCISE - Read the GeoJSON created for your favorite walks in Liverpool and calculate their length - Pro: explore the geopandas documentation and try to extract the area for the polygon covering your neighbourhood\n\n\n3.2.3 Tilesets and Mbtiles"
  },
  {
    "objectID": "dataarch.html#references",
    "href": "dataarch.html#references",
    "title": "3  Data architectures",
    "section": "3.3 References",
    "text": "3.3 References\n\nChapter 3 of the GDS book (in progress) covers traditional and more modern approaches to represent Geography as data.\nKitchin, R. (2014). The data revolution: Big data, open data, data infrastructures and their consequences. Sage.\nMaptiler.com documents on map tiles and map vector tiles."
  },
  {
    "objectID": "apis.html#lecture",
    "href": "apis.html#lecture",
    "title": "4  APIs",
    "section": "4.1 Lecture",
    "text": "4.1 Lecture\nSlides can be downloaded here"
  },
  {
    "objectID": "apis.html#lab-acquiring-data-from-the-web.",
    "href": "apis.html#lab-acquiring-data-from-the-web.",
    "title": "4  APIs",
    "section": "4.2 Lab: Acquiring data from the web.",
    "text": "4.2 Lab: Acquiring data from the web.\n\n4.2.1 Paired activity\n\n\n4.2.2 Class discussion"
  },
  {
    "objectID": "apis.html#references",
    "href": "apis.html#references",
    "title": "4  APIs",
    "section": "4.3 References",
    "text": "4.3 References\nArribas-Bel, D. (2014) “Accidental, Open and Everywhere: Emerging Data Sources for the Understanding of Cities”. Applied Geography, 49: 45-53. Goodchild, M. F. (2007). Citizens as sensors: the world of volunteered geography. GeoJournal, 69(4), 211-221. Lazer, D., & Radford, J. (2017). Data ex machina: introduction to big data. Annual Review of Sociology, 43, 19-39. Lab: Acquiring data from the web Notes:"
  },
  {
    "objectID": "mapdesign.html#lecture",
    "href": "mapdesign.html#lecture",
    "title": "5  Map design",
    "section": "5.1 Lecture",
    "text": "5.1 Lecture\nSlides can be downloaded here"
  },
  {
    "objectID": "mapdesign.html#lab-designing-maps-with-mapbox-studio-take-out-carto",
    "href": "mapdesign.html#lab-designing-maps-with-mapbox-studio-take-out-carto",
    "title": "5  Map design",
    "section": "5.2 Lab: Designing maps with Mapbox Studio (take out Carto)",
    "text": "5.2 Lab: Designing maps with Mapbox Studio (take out Carto)\n\n5.2.1 Paired activity\n\n\n5.2.2 Class discussion"
  },
  {
    "objectID": "mapdesign.html#references",
    "href": "mapdesign.html#references",
    "title": "5  Map design",
    "section": "5.3 References",
    "text": "5.3 References"
  },
  {
    "objectID": "interact.html#lecture",
    "href": "interact.html#lecture",
    "title": "6  Interactivity",
    "section": "6.1 Lecture",
    "text": "6.1 Lecture\nSlides can be downloaded here"
  },
  {
    "objectID": "interact.html#lab",
    "href": "interact.html#lab",
    "title": "6  Interactivity",
    "section": "6.2 Lab:",
    "text": "6.2 Lab:"
  },
  {
    "objectID": "interact.html#references",
    "href": "interact.html#references",
    "title": "6  Interactivity",
    "section": "6.3 References",
    "text": "6.3 References"
  },
  {
    "objectID": "choro.html#lecture",
    "href": "choro.html#lecture",
    "title": "7  Statistical visualisation",
    "section": "7.1 Lecture",
    "text": "7.1 Lecture\nSlides can be downloaded here"
  },
  {
    "objectID": "choro.html#lab",
    "href": "choro.html#lab",
    "title": "7  Statistical visualisation",
    "section": "7.2 Lab:",
    "text": "7.2 Lab:"
  },
  {
    "objectID": "choro.html#references",
    "href": "choro.html#references",
    "title": "7  Statistical visualisation",
    "section": "7.3 References",
    "text": "7.3 References"
  },
  {
    "objectID": "dashboards.html#lecture",
    "href": "dashboards.html#lecture",
    "title": "8  Dashboards",
    "section": "8.1 Lecture",
    "text": "8.1 Lecture\nSlides can be downloaded here"
  },
  {
    "objectID": "dashboards.html#lab",
    "href": "dashboards.html#lab",
    "title": "8  Dashboards",
    "section": "8.2 Lab:",
    "text": "8.2 Lab:"
  },
  {
    "objectID": "dashboards.html#references",
    "href": "dashboards.html#references",
    "title": "8  Dashboards",
    "section": "8.3 References",
    "text": "8.3 References"
  },
  {
    "objectID": "techgallery.html",
    "href": "techgallery.html",
    "title": "9  Technology Gallery",
    "section": "",
    "text": "Dani Arribas-Bel\nLecture: Technology gallery\nLab: Assignment II clinic."
  }
]